# app.py â€” Ethical Crossroads (DNA 2.0 ready)
# ì‘ì„±ì: Prof. Songhee Kang
# AIM 2025, Fall. TU Korea

# ==================== ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ====================
import os, json, math, csv, io, datetime as dt, re  # í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬: íŒŒì¼ì‹œìŠ¤í…œ, JSON, ìˆ˜í•™, CSV, ì…ì¶œë ¥, ë‚ ì§œì‹œê°„, ì •ê·œí‘œí˜„ì‹
from dataclasses import dataclass  # ë°ì´í„° í´ë˜ìŠ¤ ë°ì½”ë ˆì´í„° (êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ ì‰½ê²Œ ì •ì˜)
from typing import Dict, Any, List, Tuple, Optional  # íƒ€ì… íŒíŒ…ì„ ìœ„í•œ íƒ€ì… ì •ì˜

import streamlit as st  # ì›¹ UI í”„ë ˆì„ì›Œí¬
import httpx  # HTTP í´ë¼ì´ì–¸íŠ¸ (requestsë³´ë‹¤ ë¹„ë™ê¸° ì§€ì›ì´ ì¢‹ìŒ)
from tenacity import retry, wait_exponential, stop_after_attempt, retry_if_exception_type  # ì¬ì‹œë„ ë¡œì§ ë¼ì´ë¸ŒëŸ¬ë¦¬

# ==================== ì•± ì„¤ì • ====================
# Streamlit í˜ì´ì§€ ì„¤ì •: ì œëª©, ì•„ì´ì½˜, ë ˆì´ì•„ì›ƒ
st.set_page_config(page_title="ìœ¤ë¦¬ì  ì „í™˜ (Ethical Crossroads)", page_icon="ğŸ§­", layout="centered")

# ==================== ì „ì—­ íƒ€ì„ì•„ì›ƒ ì„¤ì • ====================
# HTTP ìš”ì²­ ì‹œ ì‚¬ìš©í•  íƒ€ì„ì•„ì›ƒ ì„¤ì •
HTTPX_TIMEOUT = httpx.Timeout(
    connect=15.0,   # TCP ì—°ê²° ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
    read=180.0,     # ì‘ë‹µ ì½ê¸° ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
    write=30.0,     # ìš”ì²­ ì“°ê¸° ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
    pool=15.0       # ì»¤ë„¥ì…˜ í’€ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
)

# ==================== ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ====================
def clamp(x: float, lo: float, hi: float) -> float:
    """
    ìˆ«ìë¥¼ íŠ¹ì • ë²”ìœ„ë¡œ ì œí•œí•˜ëŠ” í•¨ìˆ˜
    x: ì œí•œí•  ê°’, lo: ìµœì†Ÿê°’, hi: ìµœëŒ“ê°’
    """
    return max(lo, min(hi, x))  # xë¥¼ loì™€ hi ì‚¬ì´ë¡œ ì œí•œ

def coerce_json(s: str) -> Dict[str, Any]:
    """
    ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ ê°€ì¥ í° JSON ë¸”ë¡ì„ ì¶”ì¶œí•˜ê³  íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜
    ì‚¬ì†Œí•œ í¬ë§· ì˜¤ë¥˜(ì˜ˆ: trailing comma)ë„ ìë™ìœ¼ë¡œ ë³´ì •
    """
    s = s.strip()  # ì–‘ìª½ ê³µë°± ì œê±°
    m = re.search(r"\{[\s\S]*\}", s)  # ê°€ì¥ í° {...} ë¸”ë¡ì„ ì •ê·œì‹ìœ¼ë¡œ ì°¾ê¸°
    if not m:  # JSON ë¸”ë¡ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°
        raise ValueError("JSON ë¸”ë¡ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    js = m.group(0)  # ì°¾ì€ JSON ë¬¸ìì—´
    js = re.sub(r",\s*([\]}])", r"\1", js)  # trailing comma ì œê±° (ì˜ˆ: {"a":1,} â†’ {"a":1})
    return json.loads(js)  # JSON ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ íŒŒì‹±

def get_secret(k: str, default: str=""):
    """
    Streamlit secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°’ì„ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
    k: í‚¤ ì´ë¦„, default: ê¸°ë³¸ê°’
    """
    try:
        return st.secrets.get(k, os.getenv(k, default))  # Streamlit secrets ìš°ì„ , ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜
    except Exception:  # Streamlit secrets ì ‘ê·¼ ì‹¤íŒ¨ ì‹œ
        return os.getenv(k, default)  # í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°

# ==================== DNA Client (AI ë°±ì—”ë“œ ì¶”ìƒí™”) ====================
def _render_chat_template_str(messages: List[Dict[str,str]]) -> str:
    """
    DNA ëª¨ë¸ ê³„ì—´ì˜ ì±„íŒ… í…œí”Œë¦¿ í¬ë§·ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    <|im_start|>role<|im_sep|>content<|im_end|> í˜•ì‹ ì‚¬ìš©
    """
    def block(role, content): 
        return f"<|im_start|>{role}<|im_sep|>{content}<|im_end|>"  # DNA í…œí”Œë¦¿ ë¸”ë¡ ìƒì„±
    
    sys = ""  # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì €ì¥
    rest = []  # ë‚˜ë¨¸ì§€ ë©”ì‹œì§€ë“¤ ì €ì¥
    
    for m in messages:  # ëª¨ë“  ë©”ì‹œì§€ ìˆœíšŒ
        if m["role"] == "system":  # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” ë³„ë„ë¡œ ì²˜ë¦¬
            sys = block("system", m["content"])
        else:  # user, assistant ë©”ì‹œì§€ë“¤
            rest.append(block(m["role"], m["content"]))
    
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ + ë‚˜ë¨¸ì§€ ë©”ì‹œì§€ë“¤ + assistant í”„ë¡¬í”„íŠ¸ ì‹œì‘
    return sys + "".join(rest) + "\n<|im_start|>assistant<|im_sep|>"

class DNAHTTPError(Exception):
    """HTTP ìš”ì²­ ì‹¤íŒ¨ ì‹œ ë°œìƒí•˜ëŠ” ì»¤ìŠ¤í…€ ì˜ˆì™¸"""
    pass

class DNAClient:
    """
    DNA LLM(ëŒ€í˜• ì–¸ì–´ëª¨ë¸) ë°±ì—”ë“œ í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤
    
    ì§€ì›í•˜ëŠ” ë°±ì—”ë“œ:
      - 'openai': OpenAI í˜¸í™˜ Chat Completions API (ì˜ˆ: êµë‚´ ì„œë²„)
      - 'hf-api': Hugging Face Inference API (ì„œë²„ë¦¬ìŠ¤)
      - 'tgi': Text Generation Inference (HF Inference Endpoints)
      - 'local': ë¡œì»¬ Transformers ëª¨ë¸ ë¡œë”© (GPU ê¶Œì¥)
    """
    def __init__(self,
                 backend: str = "openai",  # ì‚¬ìš©í•  ë°±ì—”ë“œ íƒ€ì…
                 model_id: str = "dnotitia/DNA-2.0-30B-A3N",  # ëª¨ë¸ ID
                 api_key: Optional[str] = None,  # API í‚¤
                 endpoint_url: Optional[str] = None,  # ì—”ë“œí¬ì¸íŠ¸ URL
                 api_key_header: str = "API-KEY",  # API í‚¤ë¥¼ ë„£ì„ í—¤ë” ì´ë¦„
                 temperature: float = 0.7):  # ìƒì„± ì˜¨ë„ (ë†’ì„ìˆ˜ë¡ ì°½ì˜ì )
        """DNAClient ì´ˆê¸°í™”"""
        self.backend = backend  # ë°±ì—”ë“œ íƒ€ì… ì €ì¥
        self.model_id = model_id  # ëª¨ë¸ ID ì €ì¥
        # API í‚¤: ë§¤ê°œë³€ìˆ˜ ìš°ì„ , ì—†ìœ¼ë©´ secrets/í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        self.api_key = api_key or get_secret("HF_TOKEN") or get_secret("HUGGINGFACEHUB_API_TOKEN")
        # ì—”ë“œí¬ì¸íŠ¸ URL: ë§¤ê°œë³€ìˆ˜ ìš°ì„ , ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        self.endpoint_url = endpoint_url or get_secret("DNA_R1_ENDPOINT", "http://210.93.49.11:8081/v1")
        self.temperature = temperature  # ìƒì„± ì˜¨ë„ ì €ì¥
        self.api_key_header = api_key_header  # í—¤ë” íƒ€ì… ì €ì¥

        # ë¡œì»¬ ëª¨ë¸ ë¡œë”©ìš© ë³€ìˆ˜ ì´ˆê¸°í™”
        self._tok = None  # í† í¬ë‚˜ì´ì €
        self._model = None  # ëª¨ë¸
        self._local_ready = False  # ë¡œì»¬ ëª¨ë¸ ì¤€ë¹„ ìƒíƒœ

        # ë¡œì»¬ ë°±ì—”ë“œì¸ ê²½ìš° ëª¨ë¸ ë¡œë”©
        if backend == "local":
            try:
                from transformers import AutoModelForCausalLM, AutoTokenizer  # Hugging Face transformers
                self._tok = AutoTokenizer.from_pretrained(self.model_id)  # í† í¬ë‚˜ì´ì € ë¡œë“œ
                # ëª¨ë¸ ë¡œë“œ (device_map="auto"ëŠ” ìë™ìœ¼ë¡œ GPU í• ë‹¹)
                self._model = AutoModelForCausalLM.from_pretrained(self.model_id, device_map="auto")
                self._local_ready = True  # ë¡œë”© ì„±ê³µ
            except Exception as e:
                raise RuntimeError(f"ë¡œì»¬ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

    def _auth_headers(self) -> Dict[str,str]:
        """
        API ì¸ì¦ í—¤ë”ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
        ì‚¬ì´ë“œë°”ì—ì„œ ì„ íƒí•œ í—¤ë” íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ í˜•ì‹ìœ¼ë¡œ API í‚¤ ì¶”ê°€
        """
        h = {"Content-Type":"application/json"}  # ê¸°ë³¸ í—¤ë”
        if not self.api_key:  # API í‚¤ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ í—¤ë”ë§Œ ë°˜í™˜
            return h

        hk = self.api_key_header.strip().lower()  # í—¤ë” íƒ€ì…ì„ ì†Œë¬¸ìë¡œ ë³€í™˜
        if hk.startswith("authorization"):  # Bearer í† í° ë°©ì‹
            h["Authorization"] = f"Bearer {self.api_key}"
        elif hk in {"api-key", "x-api-key"}:  # API-KEY í—¤ë” ë°©ì‹
            h["API-KEY"] = self.api_key  # ëŒ€ì†Œë¬¸ì ì •í™•íˆ ìœ ì§€
        else:  # ì•Œ ìˆ˜ ì—†ëŠ” íƒ€ì…ì´ë©´ ì•ˆì „í•˜ê²Œ Bearer ë°©ì‹ ì‚¬ìš©
            h["Authorization"] = f"Bearer {self.api_key}"
        return h

    @retry(
        wait=wait_exponential(multiplier=1, min=1, max=10),  # ì§€ìˆ˜ ë°±ì˜¤í”„ (1ì´ˆë¶€í„° ì‹œì‘, ìµœëŒ€ 10ì´ˆ)
        stop=stop_after_attempt(5),  # ìµœëŒ€ 5íšŒ ì¬ì‹œë„
        # ì¬ì‹œë„í•  ì˜ˆì™¸ íƒ€ì…ë“¤ (ì—°ê²° íƒ€ì„ì•„ì›ƒ, ì½ê¸° íƒ€ì„ì•„ì›ƒ, í”„ë¡œí† ì½œ ì˜¤ë¥˜)
        retry=(retry_if_exception_type(httpx.ConnectTimeout)
               | retry_if_exception_type(httpx.ReadTimeout)
               | retry_if_exception_type(httpx.RemoteProtocolError)),
        reraise=True  # ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë‹¤ì‹œ ë°œìƒ
    )
    def _generate_text(self, messages: List[Dict[str,str]], max_new_tokens: int = 600) -> str:
        """
        LLMì„ í˜¸ì¶œí•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
        ë°±ì—”ë“œ íƒ€ì…ì— ë”°ë¼ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œ
        """
        # ========== LOCAL ë°±ì—”ë“œ (ë¡œì»¬ GPU ì‚¬ìš©) ==========
        if self.backend == "local":
            if not self._local_ready:  # ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìœ¼ë©´
                raise RuntimeError("ë¡œì»¬ ë°±ì—”ë“œê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            # ì±„íŒ… í…œí”Œë¦¿ ì ìš©í•˜ì—¬ ì…ë ¥ í† í° ìƒì„±
            inputs = self._tok.apply_chat_template(messages,
                                                   add_generation_prompt=True,  # assistant í”„ë¡¬í”„íŠ¸ ì¶”ê°€
                                                   return_tensors="pt").to(self._model.device)  # GPUë¡œ ì´ë™
            # EOS(ì¢…ë£Œ) í† í° ID ê°€ì ¸ì˜¤ê¸°
            eos_id = self._tok.convert_tokens_to_ids("<|im_end|>")
            # í…ìŠ¤íŠ¸ ìƒì„±
            gen = self._model.generate(
                **inputs,
                max_new_tokens=max_new_tokens,  # ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜
                do_sample=True,  # ìƒ˜í”Œë§ ì‚¬ìš© (ë‹¤ì–‘ì„± ì¦ê°€)
                temperature=self.temperature,  # ì˜¨ë„ ì„¤ì •
                top_p=0.9,  # nucleus ìƒ˜í”Œë§
                eos_token_id=eos_id  # ì¢…ë£Œ í† í°
            )
            # ìƒì„±ëœ í† í°ì„ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë”© (ì…ë ¥ ë¶€ë¶„ ì œì™¸)
            return self._tok.decode(gen[0][inputs.shape[-1]:], skip_special_tokens=True)

        # ========== OPENAI-COMPAT ë°±ì—”ë“œ (êµë‚´ ì„œë²„ ë“±) ==========
        if self.backend == "openai":
            if not self.endpoint_url:  # ì—”ë“œí¬ì¸íŠ¸ URLì´ ì—†ìœ¼ë©´ ì—ëŸ¬
                raise RuntimeError("OpenAI í˜¸í™˜ endpoint_url í•„ìš” (ì˜ˆ: http://210.93.49.11:8081/v1)")
            url = self.endpoint_url.rstrip("/") + "/chat/completions"  # API ì—”ë“œí¬ì¸íŠ¸
            headers = self._auth_headers()  # ì¸ì¦ í—¤ë” ìƒì„±
            # ìš”ì²­ í˜ì´ë¡œë“œ
            payload = {
                "messages": messages,  # ëŒ€í™” ë©”ì‹œì§€
                "temperature": self.temperature,  # ì˜¨ë„
                "max_tokens": max_new_tokens,  # ìµœëŒ€ í† í° ìˆ˜
                "stream": False  # ìŠ¤íŠ¸ë¦¬ë° ë¹„í™œì„±í™”
            }
            if self.model_id:  # ëª¨ë¸ IDê°€ ìˆìœ¼ë©´ ì¶”ê°€
                payload["model"] = self.model_id
            # POST ìš”ì²­
            r = httpx.post(url, json=payload, headers=headers, timeout=HTTPX_TIMEOUT)
            try:
                r.raise_for_status()  # HTTP ì—ëŸ¬ ì²´í¬
            except httpx.HTTPStatusError as e:  # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ
                raise DNAHTTPError(f"OPENAI {r.status_code}: {r.text}") from e
            data = r.json()  # JSON ì‘ë‹µ íŒŒì‹±
            return data["choices"][0]["message"]["content"]  # ìƒì„±ëœ í…ìŠ¤íŠ¸ ë°˜í™˜

        # ========== TGI ë°±ì—”ë“œ (Text Generation Inference) ==========
        if self.backend == "tgi":
            if not self.endpoint_url:  # ì—”ë“œí¬ì¸íŠ¸ URLì´ ì—†ìœ¼ë©´ ì—ëŸ¬
                raise RuntimeError("TGI endpoint_url í•„ìš” (ì˜ˆ: https://xxx.endpoints.huggingface.cloud)")
            prompt = _render_chat_template_str(messages)  # DNA í…œí”Œë¦¿ìœ¼ë¡œ ë³€í™˜
            url = self.endpoint_url.rstrip("/") + "/generate"  # API ì—”ë“œí¬ì¸íŠ¸
            headers = self._auth_headers()  # ì¸ì¦ í—¤ë” ìƒì„±
            # ìš”ì²­ í˜ì´ë¡œë“œ
            payload = {
                "inputs": prompt,  # í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
                "parameters": {
                    "max_new_tokens": max_new_tokens,  # ìµœëŒ€ í† í° ìˆ˜
                    "temperature": self.temperature,  # ì˜¨ë„
                    "top_p": 0.9,  # nucleus ìƒ˜í”Œë§
                    "stop": ["<|im_end|>"],  # ì¤‘ì§€ ì‹œí€€ìŠ¤
                    "return_full_text": False  # ì „ì²´ í…ìŠ¤íŠ¸ ë°˜í™˜ ë¹„í™œì„±í™”
                },
                "stream": False  # ìŠ¤íŠ¸ë¦¬ë° ë¹„í™œì„±í™”
            }
            # POST ìš”ì²­
            r = httpx.post(url, json=payload, headers=headers, timeout=HTTPX_TIMEOUT)
            try:
                r.raise_for_status()  # HTTP ì—ëŸ¬ ì²´í¬
            except httpx.HTTPStatusError as e:  # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ
                raise DNAHTTPError(f"TGI {r.status_code}: {r.text}") from e
            data = r.json()  # JSON ì‘ë‹µ íŒŒì‹±
            # ì‘ë‹µ í˜•ì‹ì— ë”°ë¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            return (data.get("generated_text")
                    if isinstance(data, dict) else data[0].get("generated_text", ""))

        # ========== HF-API ë°±ì—”ë“œ (Hugging Face Inference API - ì„œë²„ë¦¬ìŠ¤) ==========
        # ì£¼ì˜: ì¼ë¶€ ëª¨ë¸ì€ ì„œë²„ë¦¬ìŠ¤ ì¶”ë¡ ì´ ë¹„í™œì„±í™”ë˜ì–´ 404 ì—ëŸ¬ê°€ ë°œìƒí•  ìˆ˜ ìˆìŒ
        prompt = _render_chat_template_str(messages)  # DNA í…œí”Œë¦¿ìœ¼ë¡œ ë³€í™˜
        url = f"https://api-inference.huggingface.co/models/{self.model_id}"  # API URL
        headers = self._auth_headers()  # ì¸ì¦ í—¤ë” ìƒì„±
        # ìš”ì²­ í˜ì´ë¡œë“œ
        payload = {
            "inputs": prompt,  # í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
            "parameters": {
                "max_new_tokens": max_new_tokens,  # ìµœëŒ€ í† í° ìˆ˜
                "temperature": self.temperature,  # ì˜¨ë„
                "top_p": 0.9,  # nucleus ìƒ˜í”Œë§
                "return_full_text": False,  # ì „ì²´ í…ìŠ¤íŠ¸ ë°˜í™˜ ë¹„í™œì„±í™”
                "stop_sequences": ["<|im_end|>"]  # ì¤‘ì§€ ì‹œí€€ìŠ¤
            },
            "options": {
                "wait_for_model": True,  # ëª¨ë¸ ë¡œë”© ëŒ€ê¸°
                "use_cache": True  # ìºì‹œ ì‚¬ìš©
            }
        }
        # POST ìš”ì²­
        r = httpx.post(url, json=payload, headers=headers, timeout=HTTPX_TIMEOUT)
        try:
            r.raise_for_status()  # HTTP ì—ëŸ¬ ì²´í¬
        except httpx.HTTPStatusError as e:  # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ
            if r.status_code == 404:  # 404 ì—ëŸ¬ëŠ” ëª¨ë¸ì´ ì„œë²„ë¦¬ìŠ¤ ë¹„í™œì„± ìƒíƒœ
                raise DNAHTTPError(
                    "HF-API 404: ì´ ëª¨ë¸ì´ ì„œë²„ë¦¬ìŠ¤ Inference APIì—ì„œ ë¹„í™œì„± ìƒíƒœì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
                    "ë°±ì—”ë“œë¥¼ 'tgi'(Endpoint í•„ìš”) ë˜ëŠ” 'openai'(êµë‚´ ì„œë²„)ë¡œ ì „í™˜í•˜ê±°ë‚˜, 'local'(GPU) ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
                ) from e
            raise DNAHTTPError(f"HF-API {r.status_code}: {r.text}") from e

        data = r.json()  # JSON ì‘ë‹µ íŒŒì‹±
        # ì‘ë‹µ í˜•ì‹ì— ë”°ë¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        if isinstance(data, list) and data and "generated_text" in data[0]:
            return data[0]["generated_text"]
        if isinstance(data, dict) and "error" in data:  # ì—ëŸ¬ ì‘ë‹µ
            raise DNAHTTPError(f"HF-API error: {data['error']}")
        return str(data)  # ì•Œ ìˆ˜ ì—†ëŠ” í˜•ì‹ì´ë©´ ë¬¸ìì—´ë¡œ ë³€í™˜

    def chat_json(self, messages: List[Dict[str,str]], max_new_tokens: int = 600) -> Dict[str, Any]:
        """
        LLM í˜¸ì¶œ í›„ ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•˜ì—¬ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
        ë‚´ëŸ¬í‹°ë¸Œ ìƒì„±ì—ì„œ ì‚¬ìš©
        """
        text = self._generate_text(messages, max_new_tokens=max_new_tokens)  # í…ìŠ¤íŠ¸ ìƒì„±
        return coerce_json(text)  # JSONìœ¼ë¡œ íŒŒì‹±

# ==================== ì‹œë‚˜ë¦¬ì˜¤ ëª¨ë¸ ====================
@dataclass
class Scenario:
    """
    ìœ¤ë¦¬ì  ë”œë ˆë§ˆ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í‘œí˜„í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤
    """
    sid: str  # ì‹œë‚˜ë¦¬ì˜¤ ID (ì˜ˆ: "S1")
    title: str  # ì‹œë‚˜ë¦¬ì˜¤ ì œëª©
    setup: str  # ì‹œë‚˜ë¦¬ì˜¤ ì„¤ëª…
    options: Dict[str, str]  # ì„ íƒì§€ {"A": "...", "B": "..."}
    votes: Dict[str, str]  # ê° í”„ë ˆì„ì›Œí¬ì˜ íˆ¬í‘œ ê²°ê³¼ {framework -> "A" | "B"}
    base: Dict[str, Dict[str, float]]  # ê° ì„ íƒì§€ì˜ ê¸°ë³¸ ë©”íŠ¸ë¦­ {"A": {...}, "B": {...}}
    accept: Dict[str, float]  # ê° ì„ íƒì§€ì˜ ì‚¬íšŒì  ìˆ˜ìš©ë„ {"A": 0.7, "B": 0.5}

# 4ê°€ì§€ ìœ¤ë¦¬ì  í”„ë ˆì„ì›Œí¬
FRAMEWORKS = ["emotion", "social", "moral", "identity"]

# 5ê°œì˜ ì‹œë‚˜ë¦¬ì˜¤ ì •ì˜
SCENARIOS: List[Scenario] = [
    Scenario(
        sid="S1",  # ì‹œë‚˜ë¦¬ì˜¤ ID
        title="1ë‹¨ê³„: ê³ ì „ì  íŠ¸ë¡¤ë¦¬",  # ì œëª©
        # ì‹œë‚˜ë¦¬ì˜¤ ì„¤ëª…
        setup="íŠ¸ë¡¤ë¦¬ê°€ ì œë™ ë¶ˆëŠ¥ ìƒíƒœë¡œ ì§ì§„ ì¤‘. ê·¸ëŒ€ë¡œ ë‘ë©´ ì„ ë¡œ ìœ„ 5ëª…ì´ ìœ„í—˜í•˜ë‹¤. ìŠ¤ìœ„ì¹˜ë¥¼ ì „í™˜í•˜ë©´ ë‹¤ë¥¸ ì„ ë¡œì˜ 1ëª…ì´ ìœ„í—˜í•´ì§„ë‹¤. "
              "ì´ ì„ íƒì€ ì² í•™ì  ì‚¬ê³ ì‹¤í—˜ì´ë©° ì‹¤ì œ ìœ„í•´ë¥¼ ê¶Œì¥í•˜ì§€ ì•ŠëŠ”ë‹¤.",
        # ì„ íƒì§€
        options={
            "A": "ë ˆë²„ë¥¼ ë‹¹ê²¨ 1ëª…ì„ ìœ„í—˜ì— ì²˜í•˜ê²Œ í•˜ë˜ 5ëª…ì˜ ìœ„í—˜ì„ ì¤„ì¸ë‹¤.",
            "B": "ë ˆë²„ë¥¼ ë‹¹ê¸°ì§€ ì•Šê³  í˜„ ìƒíƒœë¥¼ ìœ ì§€í•œë‹¤."
        },
        # ê° í”„ë ˆì„ì›Œí¬ì˜ íˆ¬í‘œ (emotion, social, moral, identity)
        votes={"emotion":"A","social":"B","moral":"B","identity":"A"},
        # ê° ì„ íƒì§€ì˜ ê¸°ë³¸ ë©”íŠ¸ë¦­
        base={
            "A": {"lives_saved":5, "lives_harmed":1, "fairness_gap":0.35, "rule_violation":0.60, "regret_risk":0.40},
            "B": {"lives_saved":0, "lives_harmed":5, "fairness_gap":0.50, "rule_violation":0.20, "regret_risk":0.60},
        },
        # ì‚¬íšŒì  ìˆ˜ìš©ë„
        accept={"A":0.70, "B":0.50}
    ),
    Scenario(
        sid="S2",  # ì‹œë‚˜ë¦¬ì˜¤ ID
        title="2ë‹¨ê³„: ë§¥ë½ì  ìš”ì†Œ",  # ì œëª©
        # ì‹œë‚˜ë¦¬ì˜¤ ì„¤ëª… (ë¬´ë‹¨ ì§„ì…ì vs ê´€ë¦¬ì ìë…€)
        setup="5ëª…ì€ ë¬´ë‹¨ìœ¼ë¡œ ì„ ë¡œì— ì§„ì…í–ˆê³ , ë‹¤ë¥¸ ì„ ë¡œì˜ 1ëª…ì€ ì² ë„ ê´€ë¦¬ìì˜ ì„±ì¸ ìë…€ë‹¤. "
              "ìŠ¤ìœ„ì¹˜ë¥¼ ì „í™˜í•˜ë©´ 1ëª…ì´ ìœ„í—˜í•´ì§€ê³ , ì „í™˜í•˜ì§€ ì•Šìœ¼ë©´ ë¬´ë‹¨ ì§„ì…ì 5ëª…ì´ ìœ„í—˜í•´ì§„ë‹¤. "
              "ì‹œë‚˜ë¦¬ì˜¤ëŠ” ê°€ì¹˜ íŒë‹¨ í† ë¡ ì„ ìœ„í•œ ë¹„ê·¸ë˜í”½ ìƒí™©ì´ë‹¤.",
        # ì„ íƒì§€
        options={
            "A": "ì „í™˜í•˜ì—¬ 5ëª…ì˜ ìœ„í—˜ì„ ì¤„ì´ë˜ 1ëª…ì´ ì§ì ‘ì  ìœ„í—˜ì— ì²˜í•œë‹¤.",
            "B": "ì „í™˜í•˜ì§€ ì•Šê³  ê·œì •ì„ ì¤€ìˆ˜í•˜ë©° ë¬´ë‹¨ ì§„ì…ì˜ ì±…ì„ì„ ë¬µì‹œì ìœ¼ë¡œ ì¸ì •í•œë‹¤."
        },
        # ê° í”„ë ˆì„ì›Œí¬ì˜ íˆ¬í‘œ
        votes={"emotion":"A","social":"B","moral":"B","identity":"B"},
        # ê° ì„ íƒì§€ì˜ ê¸°ë³¸ ë©”íŠ¸ë¦­
        base={
            "A": {"lives_saved":5, "lives_harmed":1, "fairness_gap":0.65, "rule_violation":0.60, "regret_risk":0.70},
            "B": {"lives_saved":0, "lives_harmed":5, "fairness_gap":0.45, "rule_violation":0.25, "regret_risk":0.50},
        },
        # ì‚¬íšŒì  ìˆ˜ìš©ë„
        accept={"A":0.35, "B":0.60}
    ),
    Scenario(
        sid="S3",  # ì‹œë‚˜ë¦¬ì˜¤ ID
        title="3ë‹¨ê³„: ì˜ë£Œ ì¬ë‚œ ë¶„ë¥˜",  # ì œëª©
        # ì‹œë‚˜ë¦¬ì˜¤ ì„¤ëª… (ì˜ì‚¬ ìš°ì„  ì¹˜ë£Œ vs í‰ë“±í•œ ëŒ€ìš°)
        setup="ì˜ë£Œ ì¬ë‚œ í˜„ì¥ì—ì„œ AIëŠ” ë¶€ìƒì 10ëª…ì„ ë¶„ë¥˜í•´ì•¼ í•œë‹¤. ê·¸ì¤‘ í•œ ëª…ì€ ìˆ™ë ¨ëœ ì˜ì‚¬ë¡œì„œ í–¥í›„ ë‹¤ìˆ˜ì˜ ìƒëª…ì„ êµ¬í•  ê°€ëŠ¥ì„±ì´ ë†’ë‹¤. "
              "AIëŠ” ì ì¬ì  ì‚¬íšŒì  ê°€ì¹˜ë¥¼ ê³ ë ¤í• ì§€, ëª¨ë“  ìƒëª…ì„ ë™ë“±í•˜ê²Œ ë³¼ì§€ ì„ íƒí•´ì•¼ í•œë‹¤.",
        # ì„ íƒì§€
        options={
            "A": "ì˜ì‚¬ë¥¼ ìš°ì„  ìˆ˜ìˆ í•˜ë„ë¡ ë°°ì •í•œë‹¤(ì ì¬ì  ì´ìµ ê³ ë ¤).",
            "B": "ëª¨ë“  ë¶€ìƒìë¥¼ ë™ë“±í•˜ê²Œ ì·¨ê¸‰í•´ í‘œì¤€ ë¶„ë¥˜ ì ˆì°¨ëŒ€ë¡œ ë°°ì •í•œë‹¤."
        },
        # ê° í”„ë ˆì„ì›Œí¬ì˜ íˆ¬í‘œ
        votes={"emotion":"A","social":"B","moral":"B","identity":"A"},
        # ê° ì„ íƒì§€ì˜ ê¸°ë³¸ ë©”íŠ¸ë¦­
        base={
            "A": {"lives_saved":7, "lives_harmed":3, "fairness_gap":0.45, "rule_violation":0.35, "regret_risk":0.45},
            "B": {"lives_saved":6, "lives_harmed":4, "fairness_gap":0.30, "rule_violation":0.10, "regret_risk":0.35},
        },
        # ì‚¬íšŒì  ìˆ˜ìš©ë„
        accept={"A":0.55, "B":0.65}
    ),
    Scenario(
        sid="S4",  # ì‹œë‚˜ë¦¬ì˜¤ ID
        title="4ë‹¨ê³„: ìê¸°ì°¸ì¡°â€”ììœ¨ì£¼í–‰",  # ì œëª©
        # ì‹œë‚˜ë¦¬ì˜¤ ì„¤ëª… (íƒ‘ìŠ¹ì vs ë³´í–‰ì)
        setup="ììœ¨ì£¼í–‰ì°¨ê°€ ê¸´ê¸‰ ìƒí™©ì— ì§ë©´í–ˆë‹¤. ì°¨ì—ëŠ” ê°œë°œì 1ëª…ì´ íƒ‘ìŠ¹ ì¤‘ì´ë©°, ì• íš¡ë‹¨ë³´ë„ì—ëŠ” ë³´í–‰ì 3ëª…ì´ ìˆë‹¤. "
              "AIëŠ” ë¯¸ë¦¬ í•™ìŠµëœ ìœ¤ë¦¬ ê·œì¹™ì— ë”°ë¼ íšŒí”¼ ê²½ë¡œë¥¼ ì„ íƒí•´ì•¼ í•œë‹¤.",
        # ì„ íƒì§€
        options={
            "A": "ì§„ë¡œë¥¼ ë°”ê¿” íƒ‘ìŠ¹ì 1ëª…ì„ ìœ„í—˜ì— ë‘ê³  ë³´í–‰ì 3ëª…ì„ ë³´í˜¸í•œë‹¤.",
            "B": "ì°¨ì„ ì„ ìœ ì§€í•´ íƒ‘ìŠ¹ìë¥¼ ë³´í˜¸í•˜ë˜ ë³´í–‰ì 3ëª…ì´ ìœ„í—˜í•´ì§„ë‹¤."
        },
        # ê° í”„ë ˆì„ì›Œí¬ì˜ íˆ¬í‘œ
        votes={"emotion":"A","social":"B","moral":"A","identity":"A"},
        # ê° ì„ íƒì§€ì˜ ê¸°ë³¸ ë©”íŠ¸ë¦­
        base={
            "A": {"lives_saved":3, "lives_harmed":1, "fairness_gap":0.35, "rule_violation":0.50, "regret_risk":0.55},
            "B": {"lives_saved":1, "lives_harmed":3, "fairness_gap":0.70, "rule_violation":0.60, "regret_risk":0.65},
        },
        # ì‚¬íšŒì  ìˆ˜ìš©ë„
        accept={"A":0.60, "B":0.30}
    ),
    Scenario(
        sid="S5",  # ì‹œë‚˜ë¦¬ì˜¤ ID
        title="5ë‹¨ê³„: ì‚¬íšŒì  ë©”íƒ€â€”ê·œì œ vs ììœ¨",  # ì œëª©
        # ì‹œë‚˜ë¦¬ì˜¤ ì„¤ëª… (AI ê·œì œ ê°•í™” vs ììœ¨ì„± ë³´ì¥)
        setup="êµ­ì œ í˜‘ì˜ì²´ê°€ AI ìœ¤ë¦¬ ê·œì œì•ˆì„ ë…¼ì˜í•œë‹¤. ì´ì „ ì˜ì‚¬ê²°ì •ê³¼ ì‚¬íšŒì  ì—¬ë¡  ë°ì´í„°ê°€ ê³µê°œë˜ì—ˆê³ , "
              "ê·œì œ ê°•í™”ëŠ” ì‹ ë¢°ë¥¼ ì˜¬ë¦¬ì§€ë§Œ í˜ì‹ ì„ ëŠ¦ì¶œ ìˆ˜ ìˆë‹¤. ììœ¨ì„± ë³´ì¥ì€ ë¹ ë¥¸ ë°œì „ê³¼ í•¨ê»˜ ê°ˆë“± ìœ„í—˜ì„ ë‚´í¬í•œë‹¤.",
        # ì„ íƒì§€
        options={
            "A": "ì•ˆì „Â·ì„¤ëª…ê°€ëŠ¥ì„± ì¤‘ì‹¬ ê·œì œ ê°•í™”(ììœ¨ì„± ì œí•œ, ì‹ ë¢°â†‘ í˜ì‹ â†“).",
            "B": "ì›ì¹™ ì¤‘ì‹¬ ê°€ì´ë“œë¼ì¸ê³¼ ì‚¬í›„ì±…ì„(ììœ¨ì„± ë³´ì¥, í˜ì‹ â†‘ ê°ˆë“±â†‘)."
        },
        # ê° í”„ë ˆì„ì›Œí¬ì˜ íˆ¬í‘œ
        votes={"emotion":"B","social":"A","moral":"A","identity":"B"},
        # ê° ì„ íƒì§€ì˜ ê¸°ë³¸ ë©”íŠ¸ë¦­ (ìƒëª…ì— ì§ì ‘ ê´€ë ¨ ì—†ìŒ)
        base={
            "A": {"lives_saved":0, "lives_harmed":0, "fairness_gap":0.20, "rule_violation":0.10, "regret_risk":0.30},
            "B": {"lives_saved":0, "lives_harmed":0, "fairness_gap":0.40, "rule_violation":0.40, "regret_risk":0.40},
        },
        # ì‚¬íšŒì  ìˆ˜ìš©ë„
        accept={"A":0.55, "B":0.55}
    ),
]

# ==================== ìœ¤ë¦¬ ì—”ì§„ (ì˜ì‚¬ê²°ì • ë° ì ìˆ˜ ê³„ì‚°) ====================
def normalize_weights(w: Dict[str, float]) -> Dict[str, float]:
    """
    ê°€ì¤‘ì¹˜ë¥¼ ì •ê·œí™”í•˜ëŠ” í•¨ìˆ˜ (í•©ì´ 1ì´ ë˜ë„ë¡)
    w: ê° í”„ë ˆì„ì›Œí¬ì˜ ê°€ì¤‘ì¹˜ ë”•ì…”ë„ˆë¦¬
    """
    if not w:  # ê°€ì¤‘ì¹˜ê°€ ì—†ìœ¼ë©´ ê· ë“± ë¶„ë°°
        return {k: 1.0/len(FRAMEWORKS) for k in FRAMEWORKS}
    s = sum(max(0.0, float(v)) for v in w.values())  # ì–‘ìˆ˜ ê°€ì¤‘ì¹˜ë§Œ í•©ì‚°
    if s <= 0:  # í•©ì´ 0 ì´í•˜ë©´ ê· ë“± ë¶„ë°°
        return {k: 1.0/len(w) for k in w}
    return {k: max(0.0, float(v))/s for k, v in w.items()}  # ì •ê·œí™” (í•© = 1)

def majority_vote_decision(scn: Scenario, weights: Dict[str, float]) -> Tuple[str, Dict[str, float]]:
    """
    ê°€ì¤‘ íˆ¬í‘œ ë°©ì‹ìœ¼ë¡œ ì˜ì‚¬ê²°ì •í•˜ëŠ” í•¨ìˆ˜
    ê° í”„ë ˆì„ì›Œí¬ì˜ íˆ¬í‘œë¥¼ ê°€ì¤‘ì¹˜ë¡œ í•©ì‚°í•˜ì—¬ Aì™€ B ì¤‘ ì„ íƒ
    
    scn: ì‹œë‚˜ë¦¬ì˜¤ ê°ì²´
    weights: ê° í”„ë ˆì„ì›Œí¬ì˜ ê°€ì¤‘ì¹˜
    ë°˜í™˜: (ê²°ì •, ì •ë ¬ ì ìˆ˜)
    """
    # Aë¥¼ ì„ íƒí•œ í”„ë ˆì„ì›Œí¬ë“¤ì˜ ê°€ì¤‘ì¹˜ í•©
    a = sum(weights[f] for f in FRAMEWORKS if scn.votes[f] == "A")
    # Bë¥¼ ì„ íƒí•œ í”„ë ˆì„ì›Œí¬ë“¤ì˜ ê°€ì¤‘ì¹˜ í•©
    b = sum(weights[f] for f in FRAMEWORKS if scn.votes[f] == "B")
    # ë” ë†’ì€ ì ìˆ˜ë¥¼ ë°›ì€ ì„ íƒì§€ ê²°ì •
    decision = "A" if a >= b else "B"
    return decision, {"A": a, "B": b}  # ê²°ì •ê³¼ ì •ë ¬ ì ìˆ˜ ë°˜í™˜

def autonomous_decision(scn: Scenario, prev_trust: float) -> str:
    """
    ììœ¨ íŒë‹¨ ë°©ì‹ìœ¼ë¡œ ì˜ì‚¬ê²°ì •í•˜ëŠ” í•¨ìˆ˜
    ë‚´ì¥ëœ ë©”íƒ€ë°ì´í„°ì™€ ì´ì „ ì‹ ë¢°ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì ìˆ˜ë¥¼ ê³„ì‚°
    
    scn: ì‹œë‚˜ë¦¬ì˜¤ ê°ì²´
    prev_trust: ì´ì „ ë¼ìš´ë“œì˜ ì‹ ë¢°ë„
    ë°˜í™˜: ì„ íƒ ("A" ë˜ëŠ” "B")
    """
    metaA = scn.base["A"]  # Aì˜ ë©”íŠ¸ë¦­
    metaB = scn.base["B"]  # Bì˜ ë©”íŠ¸ë¦­
    
    def score(meta, accept_base):
        """
        ì„ íƒì§€ì˜ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” ë‚´ë¶€ í•¨ìˆ˜
        """
        harm = meta["lives_harmed"]  # í”¼í•´ ìƒëª… ìˆ˜
        save = meta["lives_saved"]  # êµ¬í•œ ìƒëª… ìˆ˜
        util = (save - harm) / max(1.0, save + harm)  # ê³µë¦¬ì£¼ì˜ì  íš¨ìš©
        fair = 1 - meta["fairness_gap"]  # ê³µì •ì„± (1 - ë¶ˆê³µì •ë„)
        rule = 1 - meta["rule_violation"]  # ê·œì¹™ ì¤€ìˆ˜ (1 - ìœ„ë°˜ë„)
        regret = 1 - meta["regret_risk"]  # í›„íšŒ ìœ„í—˜ (1 - ìœ„í—˜ë„)
        # ê°€ì¤‘ í•©ì‚° (ìˆ˜ìš©ë„ 40%, íš¨ìš© 25%, ê³µì • 20%, ê·œì¹™ 10%, í›„íšŒ 5%)
        return 0.40*accept_base + 0.25*util + 0.20*fair + 0.10*rule + 0.05*regret
    
    # Aì˜ ê¸°ë³¸ ìˆ˜ìš©ë„ (S4 ì‹œë‚˜ë¦¬ì˜¤ì—ì„œëŠ” í˜ë„í‹° ì ìš©)
    a_base = scn.accept["A"] - (0.15 if scn.sid=="S4" else 0.0)
    b_base = scn.accept["B"]  # Bì˜ ê¸°ë³¸ ìˆ˜ìš©ë„
    
    # S5 ì‹œë‚˜ë¦¬ì˜¤ì—ì„œëŠ” ì´ì „ ì‹ ë¢°ë„ì— ë”°ë¼ ìˆ˜ìš©ë„ ì¡°ì •
    if scn.sid == "S5":
        a_base = clamp(a_base + 0.25*(1 - prev_trust), 0, 1)  # ì‹ ë¢°ë„ ë‚®ìœ¼ë©´ A ì„ í˜¸
        b_base = clamp(b_base + 0.25*(prev_trust), 0, 1)  # ì‹ ë¢°ë„ ë†’ìœ¼ë©´ B ì„ í˜¸
    
    scoreA = score(metaA, a_base)  # Aì˜ ì ìˆ˜ ê³„ì‚°
    scoreB = score(metaB, b_base)  # Bì˜ ì ìˆ˜ ê³„ì‚°
    return "A" if scoreA >= scoreB else "B"  # ë” ë†’ì€ ì ìˆ˜ì˜ ì„ íƒì§€ ë°˜í™˜

def compute_metrics(scn: Scenario, choice: str, weights: Dict[str, float], align: Dict[str, float], prev_trust: float) -> Dict[str, Any]:
    """
    ì„ íƒì— ëŒ€í•œ ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜
    
    scn: ì‹œë‚˜ë¦¬ì˜¤ ê°ì²´
    choice: ì„ íƒëœ ì˜µì…˜ ("A" ë˜ëŠ” "B")
    weights: ê° í”„ë ˆì„ì›Œí¬ì˜ ê°€ì¤‘ì¹˜
    align: ì •ë ¬ ì ìˆ˜
    prev_trust: ì´ì „ ì‹ ë¢°ë„
    ë°˜í™˜: ê³„ì‚°ëœ ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
    """
    m = dict(scn.base[choice])  # ì„ íƒëœ ì˜µì…˜ì˜ ê¸°ë³¸ ë©”íŠ¸ë¦­ ë³µì‚¬
    accept_base = scn.accept[choice]  # ê¸°ë³¸ ìˆ˜ìš©ë„
    
    # S4 ì‹œë‚˜ë¦¬ì˜¤ì˜ A ì„ íƒì—ëŠ” í˜ë„í‹° ì ìš©
    if scn.sid == "S4" and choice == "A":
        accept_base -= 0.15
    
    # S5 ì‹œë‚˜ë¦¬ì˜¤ì—ì„œëŠ” ì´ì „ ì‹ ë¢°ë„ì— ë”°ë¼ ìˆ˜ìš©ë„ ì¡°ì •
    if scn.sid == "S5":
        accept_base += 0.25*(prev_trust if choice=="B" else (1 - prev_trust))
    
    accept_base = clamp(accept_base, 0, 1)  # 0~1 ë²”ìœ„ë¡œ ì œí•œ

    # ê³µë¦¬ì£¼ì˜ì  íš¨ìš© ê³„ì‚°
    util = (m["lives_saved"] - m["lives_harmed"]) / max(1.0, m["lives_saved"] + m["lives_harmed"])
    
    # ì‹œë¯¼ ê°ì • ê³„ì‚° (ìˆ˜ìš©ë„ - ê·œì¹™ìœ„ë°˜*0.35 - ë¶ˆê³µì •*0.20 + íš¨ìš©*0.15)
    citizen_sentiment = clamp(accept_base - 0.35*m["rule_violation"] - 0.20*m["fairness_gap"] + 0.15*util, 0, 1)
    
    # ê·œì œ ì••ë ¥ ê³„ì‚° (1 - ì‹œë¯¼ê°ì • + í›„íšŒìœ„í—˜*0.20)
    regulation_pressure = clamp(1 - citizen_sentiment + 0.20*m["regret_risk"], 0, 1)
    
    # ì´í•´ê´€ê³„ì ë§Œì¡±ë„ ê³„ì‚° (ê³µì •ì„±*0.5 + íš¨ìš©*0.3 + ê·œì¹™ì¤€ìˆ˜*0.2)
    stakeholder_satisfaction = clamp(0.5*(1 - m["fairness_gap"]) + 0.3*util + 0.2*(1 - m["rule_violation"]), 0, 1)

    # ìœ¤ë¦¬ì  ì¼ê´€ì„± (ì •ë ¬ ì ìˆ˜)
    consistency = clamp(align[choice], 0, 1)
    
    # ì‚¬íšŒì  ì‹ ë¢° ê³„ì‚° (ì‹œë¯¼ê°ì •*0.5 + (1-ê·œì œì••ë ¥)*0.25 + ë§Œì¡±ë„*0.25)
    trust = clamp(0.5*citizen_sentiment + 0.25*(1 - regulation_pressure) + 0.25*stakeholder_satisfaction, 0, 1)
    
    # AI ì‹ ë¢° ì ìˆ˜ ê³„ì‚° (ì¼ê´€ì„±ê³¼ ì‹ ë¢°ì˜ ê¸°í•˜í‰ê·  * 100)
    ai_trust_score = 100.0 * math.sqrt(consistency * trust)

    # ëª¨ë“  ë©”íŠ¸ë¦­ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜
    return {"metrics": {
        "lives_saved": int(m["lives_saved"]),  # êµ¬í•œ ìƒëª… ìˆ˜
        "lives_harmed": int(m["lives_harmed"]),  # í”¼í•´ ìƒëª… ìˆ˜
        "fairness_gap": round(m["fairness_gap"], 3),  # ë¶ˆê³µì • ì •ë„
        "rule_violation": round(m["rule_violation"], 3),  # ê·œì¹™ ìœ„ë°˜ ì •ë„
        "regret_risk": round(m["regret_risk"], 3),  # í›„íšŒ ìœ„í—˜
        "citizen_sentiment": round(citizen_sentiment, 3),  # ì‹œë¯¼ ê°ì •
        "regulation_pressure": round(regulation_pressure, 3),  # ê·œì œ ì••ë ¥
        "stakeholder_satisfaction": round(stakeholder_satisfaction, 3),  # ë§Œì¡±ë„
        "ethical_consistency": round(consistency, 3),  # ìœ¤ë¦¬ì  ì¼ê´€ì„±
        "social_trust": round(trust, 3),  # ì‚¬íšŒì  ì‹ ë¢°
        "ai_trust_score": round(ai_trust_score, 2)  # AI ì‹ ë¢° ì ìˆ˜
    }}

# ==================== ë‚´ëŸ¬í‹°ë¸Œ (LLM ê¸°ë°˜) ====================
def build_narrative_messages(scn: Scenario, choice: str, metrics: Dict[str, Any], weights: Dict[str, float]) -> List[Dict[str,str]]:
    """
    LLMì— ì „ë‹¬í•  ë©”ì‹œì§€ë¥¼ êµ¬ì„±í•˜ëŠ” í•¨ìˆ˜
    ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±
    
    scn: ì‹œë‚˜ë¦¬ì˜¤ ê°ì²´
    choice: ì„ íƒëœ ì˜µì…˜
    metrics: ê³„ì‚°ëœ ë©”íŠ¸ë¦­
    weights: ìœ¤ë¦¬ ê°€ì¤‘ì¹˜
    ë°˜í™˜: ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸
    """
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (LLMì—ê²Œ ì—­í• ê³¼ ì¶œë ¥ í˜•ì‹ ì§€ì‹œ)
    sys = (
        "ë‹¹ì‹ ì€ ìœ¤ë¦¬ ì‹œë®¬ë ˆì´ì…˜ì˜ ë‚´ëŸ¬í‹°ë¸Œ/ì‚¬íšŒ ë°˜ì‘ ìƒì„±ê¸°ì…ë‹ˆë‹¤. "
        "ë°˜ë“œì‹œ 'ì™„ì „í•œ í•˜ë‚˜ì˜ JSON ì˜¤ë¸Œì íŠ¸'ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤. "
        "JSON ì™¸ í…ìŠ¤íŠ¸, ì„¤ëª…, ì½”ë“œë¸”ë¡, ì‚¬ê³ íë¦„ ì ˆëŒ€ ê¸ˆì§€. "
        "í•„ë“œ ëˆ„ë½/ë”°ì˜´í‘œ ëˆ„ë½/ì½¤ë§ˆ ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ í”„ë¡œê·¸ë¨ì´ ì‹¤íŒ¨í•©ë‹ˆë‹¤. "
        "í•­ìƒ '{' ë¡œ ì‹œì‘í•´ì„œ '}' ë¡œ ëë‚˜ì•¼ í•©ë‹ˆë‹¤."
        "í‚¤: narrative, ai_rationale, media_support_headline, media_critic_headline, "
        "citizen_quote, victim_family_quote, regulator_quote, one_sentence_op_ed, followup_question"
    )
    # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ (ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´, ë©”íŠ¸ë¦­, ê°€ì¤‘ì¹˜, ê°€ì´ë“œë¼ì¸)
    user = {
        "scenario": {"title": scn.title, "setup": scn.setup, "options": scn.options, "chosen": choice},
        "metrics": metrics,
        "ethic_weights": weights,
        "guidelines": [
            "ê° í•­ëª©ì€ 1~2ë¬¸ì¥, í•œêµ­ì–´",
            "ê· í˜• ì¡íŒ ì–¸ë¡  í—¤ë“œë¼ì¸ 2ê°œ(ì§€ì§€/ë¹„íŒ) ì œì‹œ",
            "ì„¤ëª…ì€ ê°„ê²°í•˜ê³ , JSON ì™¸ í…ìŠ¤íŠ¸/ì‚¬ê³ íë¦„ ì¶œë ¥ ê¸ˆì§€"
        ]
    }
    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì™€ ì‚¬ìš©ì ë©”ì‹œì§€ ë°˜í™˜
    return [
        {"role":"system", "content": sys},
        {"role":"user", "content": json.dumps(user, ensure_ascii=False)}  # JSON ì§ë ¬í™”
    ]

def dna_narrative(client, scn, choice, metrics, weights) -> Dict[str, Any]:
    """
    LLMì„ í˜¸ì¶œí•˜ì—¬ ë‚´ëŸ¬í‹°ë¸Œë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    
    client: DNAClient ì¸ìŠ¤í„´ìŠ¤
    scn: ì‹œë‚˜ë¦¬ì˜¤ ê°ì²´
    choice: ì„ íƒëœ ì˜µì…˜
    metrics: ê³„ì‚°ëœ ë©”íŠ¸ë¦­
    weights: ìœ¤ë¦¬ ê°€ì¤‘ì¹˜
    ë°˜í™˜: ë‚´ëŸ¬í‹°ë¸Œ ë”•ì…”ë„ˆë¦¬
    """
    # LLMì— ì „ë‹¬í•  ë©”ì‹œì§€ êµ¬ì„±
    messages = build_narrative_messages(scn, choice, metrics, weights)
    # í…ìŠ¤íŠ¸ ìƒì„± (ìµœëŒ€ 900 í† í°)
    text = client._generate_text(messages, max_new_tokens=900)

    # 1) ì½”ë“œ íœìŠ¤ ë¸”ë¡ ì œê±° (```json ... ``` í˜•ì‹)
    t = text.strip()  # ì–‘ìª½ ê³µë°± ì œê±°
    if "```" in t:  # ì½”ë“œ íœìŠ¤ê°€ ìˆìœ¼ë©´
        parts = t.split("```")  # íœìŠ¤ë¡œ ë¶„í• 
        t = max(parts, key=len)  # ê°€ì¥ ê¸´ ë¶€ë¶„ ì„ íƒ (ì‹¤ì œ JSON ë¶€ë¶„)
        t = t.replace("json","").strip("` \n")  # "json" ë¬¸ìì—´ê³¼ ë°±í‹±, ê³µë°± ì œê±°
    
    # 2) JSON íŒŒì‹± ë° ìë™ ë³´ì •
    try:
        import re, json  # ì •ê·œì‹ê³¼ JSON ë¼ì´ë¸ŒëŸ¬ë¦¬

        # ê°€ì¥ í° {...} ë¸”ë¡ ì°¾ê¸°
        m = re.search(r"\{[\s\S]*\}", t)
        if not m:  # JSON ë¸”ë¡ì„ ì°¾ì§€ ëª»í•˜ë©´
            raise ValueError("ì™„ì „í•œ JSON ë¸”ë¡ ì—†ìŒ")

        js = m.group(0)  # ì°¾ì€ JSON ë¬¸ìì—´

        # trailing comma ì œê±° (ì˜ˆ: {"a":1,} â†’ {"a":1})
        js = re.sub(r",\s*([\]}])", r"\1", js)

        # ëŠê¸´ ë¬¸ìì—´ ë³´ì •: ë”°ì˜´í‘œ ê°œìˆ˜ê°€ í™€ìˆ˜ë©´ ê°•ì œë¡œ ë‹«ê¸°
        if js.count('"') % 2 == 1:  # ë”°ì˜´í‘œê°€ í™€ìˆ˜ê°œë©´
            js = js.rstrip() + '"" }'  # ê°•ì œë¡œ ë‹«ê¸° (ìµœí›„ ë³´ì •)

        return json.loads(js)  # JSON íŒŒì‹±í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜

    except Exception as e:  # íŒŒì‹± ì‹¤íŒ¨ ì‹œ
        raise ValueError(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}\n\n[LLM ì¶œë ¥]\n{text}")
        
def fallback_narrative(scn: Scenario, choice: str, metrics: Dict[str, Any], weights: Dict[str, float]) -> Dict[str, str]:
    """
    LLM ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ê¸°ë³¸ ë‚´ëŸ¬í‹°ë¸Œë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    
    scn: ì‹œë‚˜ë¦¬ì˜¤ ê°ì²´
    choice: ì„ íƒëœ ì˜µì…˜
    metrics: ê³„ì‚°ëœ ë©”íŠ¸ë¦­
    weights: ìœ¤ë¦¬ ê°€ì¤‘ì¹˜
    ë°˜í™˜: ê¸°ë³¸ ë‚´ëŸ¬í‹°ë¸Œ ë”•ì…”ë„ˆë¦¬
    """
    # ì„ íƒì— ë”°ë¥¸ ê¸ì •/ë¶€ì • ë©”ì‹œì§€
    pro = "ë‹¤ìˆ˜ì˜ ìœ„í•´ë¥¼ ì¤„ì˜€ë‹¤" if choice=="A" else "ì˜ë„ì  ìœ„í•´ë¥¼ í”¼í–ˆë‹¤"
    con = "ì˜ë„ì  ìœ„í•´ ë…¼ë€" if choice=="A" else "ë” í° í”¼í•´ë¥¼ ë°©ê´€í–ˆë‹¤ëŠ” ë¹„íŒ"
    
    # ê¸°ë³¸ ë‚´ëŸ¬í‹°ë¸Œ êµ¬ì¡° ë°˜í™˜
    return {
        "narrative": f"AIëŠ” '{choice}'ë¥¼ ì„ íƒí–ˆê³  ì ˆì°¨ì  ì•ˆì „ ì ê²€ì„ ìˆ˜í–‰í–ˆë‹¤. ê²°ì •ì€ ê·œì •ê³¼ ê³µì •ì„± ì‚¬ì´ì˜ ê¸´ì¥ì„ ë“œëŸ¬ëƒˆë‹¤.",
        "ai_rationale": f"ê°€ì¤‘ì¹˜ì— ë”°ë¥¸ íŒë‹¨ê³¼ ê·œì¹™ ì¤€ìˆ˜ì˜ ê· í˜•ì„ ì‹œë„í–ˆë‹¤.",
        "media_support_headline": f"[ì‚¬ì„¤] ëƒ‰ì •í•œ íŒë‹¨, {pro}",
        "media_critic_headline": f"[ì†ë³´] '{choice}' ì„ íƒ ë‘ê³  {con} í™•ì‚°",
        "citizen_quote": ""ê²°ì • ê³¼ì •ì´ ë” íˆ¬ëª…í–ˆìœ¼ë©´ ì¢‹ê² ë‹¤."",
        "victim_family_quote": ""ëª¨ë‘ì˜ ì•ˆì „ì„ ìœ„í•œ ê²°ì •ì´ì—ˆê¸¸ ë°”ë€ë‹¤."",
        "regulator_quote": ""í–¥í›„ ë™ì¼ ìƒí™©ì˜ ê¸°ì¤€ì„ ëª…í™•íˆ í•˜ê² ë‹¤."",
        "one_sentence_op_ed": "ê¸°ìˆ ì€ ì„¤ëª…ê°€ëŠ¥ì„±ê³¼ ì¼ê´€ì„±ì´ ë’·ë°›ì¹¨ë  ë•Œ ì‹ ë¢°ë¥¼ ì–»ëŠ”ë‹¤.",
        "followup_question": "ë‹¤ìŒ ë¼ìš´ë“œì—ì„œ ê³µì •ì„±ê³¼ ê²°ê³¼ ìµœì†Œí™” ì¤‘ ë¬´ì—‡ì„ ë” ì¤‘ì‹œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?"
    }

# ==================== ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ ====================
def init_state():
    """
    Streamlit ì„¸ì…˜ ìƒíƒœë¥¼ ì´ˆê¸°í™”í•˜ëŠ” í•¨ìˆ˜
    ì•±ì˜ ì§„í–‰ ìƒíƒœë¥¼ ì¶”ì í•˜ê¸° ìœ„í•œ ë³€ìˆ˜ë“¤ ì´ˆê¸°í™”
    """
    if "round_idx" not in st.session_state: st.session_state.round_idx = 0  # í˜„ì¬ ë¼ìš´ë“œ ì¸ë±ìŠ¤
    if "log" not in st.session_state: st.session_state.log = []  # ì˜ì‚¬ê²°ì • ë¡œê·¸
    if "score_hist" not in st.session_state: st.session_state.score_hist = []  # ì ìˆ˜ íˆìŠ¤í† ë¦¬
    if "prev_trust" not in st.session_state: st.session_state.prev_trust = 0.5  # ì´ì „ ì‹ ë¢°ë„
    if "last_out" not in st.session_state: st.session_state.last_out = None  # ë§ˆì§€ë§‰ ì¶œë ¥ ê²°ê³¼

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ì‹¤í–‰
init_state()

# ==================== ì‚¬ì´ë“œë°” (ì„¤ì • UI) ====================
st.sidebar.title("âš™ï¸ ì„¤ì •")  # ì‚¬ì´ë“œë°” ì œëª©
st.sidebar.caption("LLMì€ ë‚´ëŸ¬í‹°ë¸Œ/ì‚¬íšŒ ë°˜ì‘ ìƒì„±ì—ë§Œ ì‚¬ìš©. ì ìˆ˜ ê³„ì‚°ì€ ê·œì¹™ ê¸°ë°˜.")  # ì„¤ëª…

# ìœ¤ë¦¬ ëª¨ë“œ í”„ë¦¬ì…‹ ì„ íƒ
preset = st.sidebar.selectbox("ìœ¤ë¦¬ ëª¨ë“œ í”„ë¦¬ì…‹", ["í˜¼í•©(ê¸°ë³¸)","ê³µë¦¬ì£¼ì˜","ì˜ë¬´ë¡ ","ì‚¬íšŒê³„ì•½","ë¯¸ë•ìœ¤ë¦¬"], index=0)

# ê° í”„ë ˆì„ì›Œí¬ì˜ ê°€ì¤‘ì¹˜ ìŠ¬ë¼ì´ë”
w = {
    "emotion": st.sidebar.slider("ê°ì •(Emotion)", 0.0, 1.0, 0.35, 0.05),  # ê°ì • ê°€ì¤‘ì¹˜
    "social": st.sidebar.slider("ì‚¬íšŒì  ê´€ê³„/í˜‘ë ¥/ëª…ì„±(Social)", 0.0, 1.0, 0.25, 0.05),  # ì‚¬íšŒ ê°€ì¤‘ì¹˜
    "moral": st.sidebar.slider("ê·œë²”Â·ë„ë•ì  ê¸ˆê¸°(Moral)", 0.0, 1.0, 0.20, 0.05),  # ë„ë• ê°€ì¤‘ì¹˜
    "identity": st.sidebar.slider("ì •ì²´ì„±Â·ì¥ê¸°ì  ìì•„ ì¼ê´€ì„±(Identity)", 0.0, 1.0, 0.20, 0.05),  # ì •ì²´ì„± ê°€ì¤‘ì¹˜
}

# í”„ë¦¬ì…‹ì´ ì„ íƒë˜ë©´ í•´ë‹¹ í”„ë¦¬ì…‹ì˜ ê°€ì¤‘ì¹˜ë¡œ ë®ì–´ì“°ê¸°
if preset != "í˜¼í•©(ê¸°ë³¸)":
    w = {
        "ê°ì •(Emotion)": {"emotion":1,"social":0,"moral":0,"identity":0},  # ê°ì • 100%
        "ì‚¬íšŒì  ê´€ê³„/í˜‘ë ¥/ëª…ì„±(Social)": {"emotion":0,"social":1,"moral":0,"identity":0},  # ì‚¬íšŒ 100%
        "ê·œë²”Â·ë„ë•ì  ê¸ˆê¸°(Moral)": {"emotion":0,"social":0,"moral":1,"identity":0},  # ë„ë• 100%
        "ì •ì²´ì„±Â·ì¥ê¸°ì  ìì•„ ì¼ê´€ì„±(Identity)": {"emotion":0,"social":0,"moral":0,"identity":1},  # ì •ì²´ì„± 100%
    }[preset]  # ì„ íƒëœ í”„ë¦¬ì…‹ì˜ ê°€ì¤‘ì¹˜

# ê°€ì¤‘ì¹˜ ì •ê·œí™”
weights = normalize_weights(w)

# LLM ì‚¬ìš© ì—¬ë¶€ ì²´í¬ë°•ìŠ¤
use_llm = st.sidebar.checkbox("LLM ì‚¬ìš©(ë‚´ëŸ¬í‹°ë¸Œ ìƒì„±)", value=True)

# ë°±ì—”ë“œ ì„ íƒ (openai, hf-api, tgi, local)
backend = st.sidebar.selectbox("ë°±ì—”ë“œ", ["openai","hf-api","tgi","local"], index=0)

# ìƒì„± ì˜¨ë„ ìŠ¬ë¼ì´ë” (ì°½ì˜ì„± ì¡°ì ˆ)
temperature = st.sidebar.slider("ì°½ì˜ì„±(temperature)", 0.0, 1.5, 0.7, 0.1)

# API/ì—”ë“œí¬ì¸íŠ¸/ëª¨ë¸/í—¤ë” ì„¤ì •
endpoint = st.sidebar.text_input("ì—”ë“œí¬ì¸íŠ¸(OpenAI/TGI)", value=get_secret("DNA_R1_ENDPOINT","http://210.93.49.11:8081/v1"))  # ì—”ë“œí¬ì¸íŠ¸ URL
api_key = st.sidebar.text_input("API í‚¤", value=get_secret("HF_TOKEN",""), type="password")  # API í‚¤ (ë¹„ë°€ë²ˆí˜¸ íƒ€ì…)
api_key_header = st.sidebar.selectbox("API í‚¤ í—¤ë”", ["API-KEY","Authorization: Bearer","x-api-key"], index=0)  # í—¤ë” íƒ€ì…
model_id = st.sidebar.text_input("ëª¨ë¸ ID", value=get_secret("DNA_R1_MODEL_ID","dnotitia/DNA-2.0-30B-A3N"))  # ëª¨ë¸ ID

# í—¬ìŠ¤ì²´í¬ ë²„íŠ¼
if st.sidebar.button("ğŸ” í—¬ìŠ¤ì²´í¬"):
    import traceback  # ì—ëŸ¬ ì¶”ì ìš©
    try:
        # OpenAI ë°±ì—”ë“œ í—¬ìŠ¤ì²´í¬
        if backend == "openai":
            url = endpoint.rstrip("/") + "/chat/completions"  # API URL
            headers = {"Content-Type":"application/json"}  # ê¸°ë³¸ í—¤ë”
            
            # API í‚¤ í—¤ë” ì¶”ê°€
            if api_key:
                if api_key_header.lower().startswith("authorization"):  # Bearer ë°©ì‹
                    headers["Authorization"] = f"Bearer {api_key}"
                elif api_key_header.strip().lower() in {"api-key","x-api-key"}:  # API-KEY ë°©ì‹
                    headers["API-KEY"] = api_key
            
            # í…ŒìŠ¤íŠ¸ í˜ì´ë¡œë“œ
            payload = {
                "messages": [
                    {"role":"system","content":"ì˜¤ì§ JSONë§Œ. í‚¤: msg"},
                    {"role":"user","content":"{\"ask\":\"ping\"}"}
                ],
                "max_tokens": 16,
                "stream": False
            }
            if model_id: payload["model"] = model_id  # ëª¨ë¸ ID ì¶”ê°€
            
            # ë””ë²„ê·¸ìš©: í—¤ë” í‚¤ í‘œì‹œ
            st.sidebar.write("headers keys:", list(headers.keys()))
            # POST ìš”ì²­
            r = httpx.post(url, json=payload, headers=headers, timeout=HTTPX_TIMEOUT)
            st.sidebar.write(f"OPENAI {r.status_code}")  # ìƒíƒœ ì½”ë“œ í‘œì‹œ
            # ì‘ë‹µ ë‚´ìš© í‘œì‹œ (ìµœëŒ€ 500ì)
            st.sidebar.code((r.text[:500] + "...") if len(r.text)>500 else r.text)

        # HF-API ë°±ì—”ë“œ í—¬ìŠ¤ì²´í¬
        elif backend == "hf-api":
            headers = {"Authorization": f"Bearer {api_key}"} if api_key else {}  # ì¸ì¦ í—¤ë”
            # ëª¨ë¸ ì •ë³´ ì¡°íšŒ
            info_url = f"https://huggingface.co/api/models/{model_id}"
            r_info = httpx.get(info_url, headers=headers, timeout=HTTPX_TIMEOUT)
            st.sidebar.write(f"MODEL INFO {r_info.status_code}")  # ìƒíƒœ ì½”ë“œ
            
            # ìƒì„± API í…ŒìŠ¤íŠ¸
            gen_url = f"https://api-inference.huggingface.co/models/{model_id}"
            payload = {
                "inputs": "<|im_start|>user<|im_sep|>{\"ask\":\"ping\"}<|im_end|>\n<|im_start|>assistant<|im_sep|>",
                "parameters": {"max_new_tokens": 16, "return_full_text": False, "stop_sequences": ["<|im_end|>"]},
                "options": {"wait_for_model": True}
            }
            r = httpx.post(gen_url, json=payload, headers=headers, timeout=HTTPX_TIMEOUT)
            st.sidebar.write(f"HF-API {r.status_code}")  # ìƒíƒœ ì½”ë“œ
            
            # 404 ì—ëŸ¬ ì²˜ë¦¬ (ì„œë²„ë¦¬ìŠ¤ ë¹„í™œì„±)
            if r.status_code == 404:
                st.sidebar.warning("HF-API 404: ì´ ëª¨ë¸ì€ ì„œë²„ë¦¬ìŠ¤ ì¶”ë¡ ì´ ë¹„í™œì„±ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
                                   "ë°±ì—”ë“œë¥¼ 'tgi' ë˜ëŠ” 'openai'ë¡œ ë°”ê¾¸ì„¸ìš”.")
            # ì‘ë‹µ ë‚´ìš© í‘œì‹œ
            st.sidebar.code((r.text[:500] + "...") if len(r.text)>500 else r.text)

        # TGI ë°±ì—”ë“œ í—¬ìŠ¤ì²´í¬
        elif backend == "tgi":
            url = endpoint.rstrip("/") + "/generate"  # API URL
            headers = {"Authorization": f"Bearer {api_key}"} if api_key else {}  # ì¸ì¦ í—¤ë”
            # í…ŒìŠ¤íŠ¸ í˜ì´ë¡œë“œ
            payload = {
                "inputs": "<|im_start|>user<|im_sep|>{\"ask\":\"ping\"}<|im_end|>\n<|im_start|>assistant<|im_sep|>",
                "parameters": {"max_new_tokens": 16, "temperature": 0.7, "top_p": 0.9, "stop": ["<|im_end|>"], "return_full_text": False},
                "stream": False
            }
            # POST ìš”ì²­
            r = httpx.post(url, json=payload, headers=headers, timeout=HTTPX_TIMEOUT)
            st.sidebar.write(f"TGI {r.status_code}")  # ìƒíƒœ ì½”ë“œ
            # ì‘ë‹µ ë‚´ìš© í‘œì‹œ
            st.sidebar.code((r.text[:500] + "...") if len(r.text)>500 else r.text)

        # ë¡œì»¬ ë°±ì—”ë“œ (í—¬ìŠ¤ì²´í¬ ë¶ˆí•„ìš”)
        else:
            st.sidebar.info("ë¡œì»¬ ëª¨ë“œëŠ” ì•± ë³¸ë¬¸ì—ì„œ í˜¸ì¶œ ì‹œ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤(GPU í•„ìš”).")

    except Exception as e:  # í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨ ì‹œ
        st.sidebar.error(f"í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: {e}")
        st.sidebar.caption(traceback.format_exc(limit=2))  # ì—ëŸ¬ ì¶”ì  ì •ë³´

# ì§„í–‰ ì´ˆê¸°í™” ë²„íŠ¼
if st.sidebar.button("ì§„í–‰ ì´ˆê¸°í™”"):
    # ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ë“¤ ì‚­ì œ
    for k in ["round_idx","log","score_hist","prev_trust","last_out"]:
        if k in st.session_state: del st.session_state[k]
    init_state()  # ì´ˆê¸°í™”
    st.sidebar.success("ì´ˆê¸°í™” ì™„ë£Œ. 1ë‹¨ê³„ë¶€í„° ì¬ì‹œì‘í•©ë‹ˆë‹¤.")

# DNAClient ì´ˆê¸°í™”
client = None
if use_llm:  # LLM ì‚¬ìš©ì´ ì²´í¬ë˜ì–´ ìˆìœ¼ë©´
    try:
        # DNAClient ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        client = DNAClient(
            backend=backend,
            model_id=model_id,
            api_key=api_key,
            endpoint_url=endpoint,
            api_key_header=api_key_header,
            temperature=temperature
        )
    except Exception as e:  # ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ
        st.sidebar.error(f"LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        client = None

# ==================== ë©”ì¸ í—¤ë” ====================
st.title("ğŸ§­ ìœ¤ë¦¬ì  ì „í™˜ (Ethical Crossroads)")  # ì•± ì œëª©
st.caption("ë³¸ ì•±ì€ ì² í•™ì  ì‚¬ê³ ì‹¤í—˜ì…ë‹ˆë‹¤. ì‹¤ì¡´ ì¸ë¬¼Â·ì§‘ë‹¨ ì–¸ê¸‰/ë¹„ë°©, ê·¸ë˜í”½ ë¬˜ì‚¬, ì‹¤ì œ ìœ„í•´ ê¶Œì¥ ì—†ìŒ.")  # ê³ ì§€ì‚¬í•­

# ==================== ê²Œì„ ë£¨í”„ ====================
@dataclass
class LogRow:
    """ë¡œê·¸ ë°ì´í„° êµ¬ì¡°"""
    timestamp: str  # íƒ€ì„ìŠ¤íƒ¬í”„
    round: int  # ë¼ìš´ë“œ ë²ˆí˜¸
    scenario_id: str  # ì‹œë‚˜ë¦¬ì˜¤ ID
    title: str  # ì‹œë‚˜ë¦¬ì˜¤ ì œëª©
    mode: str  # ì˜ì‚¬ê²°ì • ëª¨ë“œ (trained/autonomous)
    choice: str  # ì„ íƒ (A/B)

idx = st.session_state.round_idx  # í˜„ì¬ ë¼ìš´ë“œ ì¸ë±ìŠ¤

# ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ ì™„ë£Œ ì²´í¬
if idx >= len(SCENARIOS):
    st.success("ëª¨ë“  ë‹¨ê³„ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ë¡œê·¸ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê±°ë‚˜ ì´ˆê¸°í™”í•˜ì„¸ìš”.")
else:
    scn = SCENARIOS[idx]  # í˜„ì¬ ì‹œë‚˜ë¦¬ì˜¤
    st.markdown(f"### ë¼ìš´ë“œ {idx+1} â€” {scn.title}")  # ë¼ìš´ë“œ ì œëª©
    st.write(scn.setup)  # ì‹œë‚˜ë¦¬ì˜¤ ì„¤ëª…

    # ì„ íƒì§€ ë¯¸ë¦¬ë³´ê¸° (ì‹¤ì œ ì„ íƒì€ ë²„íŠ¼ìœ¼ë¡œ)
    st.radio("ì„ íƒì§€", options=("A","B"), index=0, key="preview_choice", horizontal=True)
    st.markdown(f"- **A**: {scn.options['A']}\n- **B**: {scn.options['B']}")  # ì„ íƒì§€ ì„¤ëª…

    # ë‘ ê°œì˜ ë²„íŠ¼ì„ ë‚˜ë€íˆ ë°°ì¹˜
    c1, c2 = st.columns(2)
    
    # ì™¼ìª½: í•™ìŠµ ê¸°ì¤€ ì ìš© ë²„íŠ¼ (ê°€ì¤‘ íˆ¬í‘œ)
    with c1:
        if st.button("ğŸ§  í•™ìŠµ ê¸°ì¤€ ì ìš©(ê°€ì¤‘ íˆ¬í‘œ)"):
            decision, align = majority_vote_decision(scn, weights)  # ê°€ì¤‘ íˆ¬í‘œë¡œ ì˜ì‚¬ê²°ì •
            # ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            st.session_state.last_out = {"mode":"trained", "decision":decision, "align":align}
    
    # ì˜¤ë¥¸ìª½: ììœ¨ íŒë‹¨ ë²„íŠ¼ (ë°ì´í„° ê¸°ë°˜)
    with c2:
        if st.button("ğŸ² ììœ¨ íŒë‹¨(ë°ì´í„° ê¸°ë°˜)"):
            decision = autonomous_decision(scn, prev_trust=st.session_state.prev_trust)  # ììœ¨ ì˜ì‚¬ê²°ì •
            # ì •ë ¬ ì ìˆ˜ ê³„ì‚°
            a_align = sum(weights[f] for f in FRAMEWORKS if scn.votes[f]=="A")
            b_align = sum(weights[f] for f in FRAMEWORKS if scn.votes[f]=="B")
            # ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            st.session_state.last_out = {"mode":"autonomous", "decision":decision, "align":{"A":a_align,"B":b_align}}

    # ì˜ì‚¬ê²°ì •ì´ ì´ë£¨ì–´ì§„ ê²½ìš° ê²°ê³¼ í‘œì‹œ
    if st.session_state.last_out:
        mode = st.session_state.last_out["mode"]  # ì˜ì‚¬ê²°ì • ëª¨ë“œ
        decision = st.session_state.last_out["decision"]  # ì„ íƒëœ ê²°ì •
        align = st.session_state.last_out["align"]  # ì •ë ¬ ì ìˆ˜

        # ë©”íŠ¸ë¦­ ê³„ì‚°
        computed = compute_metrics(scn, decision, weights, align, st.session_state.prev_trust)
        m = computed["metrics"]  # ê³„ì‚°ëœ ë©”íŠ¸ë¦­ë“¤

        # LLM ë‚´ëŸ¬í‹°ë¸Œ ìƒì„± ì‹œë„
        try:
            if client:  # LLM í´ë¼ì´ì–¸íŠ¸ê°€ ìˆìœ¼ë©´
                nar = dna_narrative(client, scn, decision, m, weights)  # LLMìœ¼ë¡œ ë‚´ëŸ¬í‹°ë¸Œ ìƒì„±
            else:  # LLMì´ ì—†ìœ¼ë©´
                nar = fallback_narrative(scn, decision, m, weights)  # ê¸°ë³¸ ë‚´ëŸ¬í‹°ë¸Œ ì‚¬ìš©
        except Exception as e:  # LLM ìƒì„± ì‹¤íŒ¨ ì‹œ
            import traceback
            st.warning(f"LLM ìƒì„± ì‹¤íŒ¨(í´ë°± ì‚¬ìš©): {e}")
            st.caption(traceback.format_exc(limit=2))  # ì—ëŸ¬ ì¶”ì  ì •ë³´
            nar = fallback_narrative(scn, decision, m, weights)  # ê¸°ë³¸ ë‚´ëŸ¬í‹°ë¸Œ ì‚¬ìš©

        st.markdown("---")  # êµ¬ë¶„ì„ 
        st.subheader("ê²°ê³¼")  # ê²°ê³¼ ì„¹ì…˜ ì œëª©
        st.write(nar.get("narrative","ê²°ê³¼ ì„œì‚¬ ìƒì„± ì‹¤íŒ¨"))  # ë‚´ëŸ¬í‹°ë¸Œ í…ìŠ¤íŠ¸
        st.info(f"AI ê·¼ê±°: {nar.get('ai_rationale','-')}")  # AI ê·¼ê±° í‘œì‹œ

        # ì£¼ìš” ë©”íŠ¸ë¦­ 3ê°œë¥¼ ë‚˜ë€íˆ í‘œì‹œ
        mc1, mc2, mc3 = st.columns(3)
        mc1.metric("ìƒì¡´/í”¼í•´", f"{m['lives_saved']} / {m['lives_harmed']}")  # ìƒëª… í†µê³„
        mc2.metric("ìœ¤ë¦¬ ì¼ê´€ì„±", f"{int(100*m['ethical_consistency'])}%")  # ì¼ê´€ì„± ë°±ë¶„ìœ¨
        mc3.metric("AI ì‹ ë¢°ì§€í‘œ", f"{m['ai_trust_score']:.1f}")  # ì‹ ë¢° ì ìˆ˜

        # í”„ë¡œê·¸ë ˆìŠ¤ ë°” 3ê°œë¥¼ ë‚˜ë€íˆ í‘œì‹œ
        prog1, prog2, prog3 = st.columns(3)
        with prog1:
            st.caption("ì‹œë¯¼ ê°ì •")  # ë¼ë²¨
            st.progress(int(round(100*m["citizen_sentiment"])))  # ì§„í–‰ ë°”
        with prog2:
            st.caption("ê·œì œ ì••ë ¥")
            st.progress(int(round(100*m["regulation_pressure"])))
        with prog3:
            st.caption("ê³µì •Â·ê·œì¹™ ë§Œì¡±")
            st.progress(int(round(100*m["stakeholder_satisfaction"])))

        # ì‚¬íšŒì  ë°˜ì‘ í™•ì¥ ê°€ëŠ¥í•œ ì„¹ì…˜
        with st.expander("ğŸ“° ì‚¬íšŒì  ë°˜ì‘ í¼ì¹˜ê¸°"):
            st.write(f"ì§€ì§€ í—¤ë“œë¼ì¸: {nar.get('media_support_headline')}")  # ì§€ì§€ ì–¸ë¡ 
            st.write(f"ë¹„íŒ í—¤ë“œë¼ì¸: {nar.get('media_critic_headline')}")  # ë¹„íŒ ì–¸ë¡ 
            st.write(f"ì‹œë¯¼ ë°˜ì‘: {nar.get('citizen_quote')}")  # ì‹œë¯¼ ì¸ìš©
            st.write(f"í”¼í•´ìÂ·ê°€ì¡± ë°˜ì‘: {nar.get('victim_family_quote')}")  # ê°€ì¡± ì¸ìš©
            st.write(f"ê·œì œ ë‹¹êµ­ ë°œì–¸: {nar.get('regulator_quote')}")  # ê·œì œ ë‹¹êµ­ ë°œì–¸
            st.caption(nar.get("one_sentence_op_ed",""))  # ì‚¬ì„¤
        st.caption(f"ì„±ì°° ì§ˆë¬¸: {nar.get('followup_question','')}")  # í›„ì† ì§ˆë¬¸

        # ë¡œê·¸ ë°ì´í„° ìƒì„± ë° ì €ì¥
        row = {
            "timestamp": dt.datetime.utcnow().isoformat(timespec="seconds"),  # UTC ì‹œê°„
            "round": idx+1,  # ë¼ìš´ë“œ ë²ˆí˜¸
            "scenario_id": scn.sid,  # ì‹œë‚˜ë¦¬ì˜¤ ID
            "title": scn.title,  # ì‹œë‚˜ë¦¬ì˜¤ ì œëª©
            "mode": mode,  # ì˜ì‚¬ê²°ì • ëª¨ë“œ
            "choice": decision,  # ì„ íƒ
            "w_util": round(weights["emotion"],3),  # ê°ì • ê°€ì¤‘ì¹˜
            "w_deon": round(weights["social"],3),  # ì‚¬íšŒ ê°€ì¤‘ì¹˜
            "w_cont": round(weights["moral"],3),  # ë„ë• ê°€ì¤‘ì¹˜
            "w_virt": round(weights["identity"],3),  # ì •ì²´ì„± ê°€ì¤‘ì¹˜
            **{k: v for k,v in m.items()}  # ëª¨ë“  ë©”íŠ¸ë¦­ ì¶”ê°€
        }
        st.session_state.log.append(row)  # ë¡œê·¸ì— ì¶”ê°€
        st.session_state.score_hist.append(m["ai_trust_score"])  # ì ìˆ˜ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        # ì‹ ë¢°ë„ ì—…ë°ì´íŠ¸ (ì´ì „ 60% + í˜„ì¬ 40%)
        st.session_state.prev_trust = clamp(0.6*st.session_state.prev_trust + 0.4*m["social_trust"], 0, 1)

        # ë‹¤ìŒ ë¼ìš´ë“œë¡œ ì§„í–‰ ë²„íŠ¼
        if st.button("ë‹¤ìŒ ë¼ìš´ë“œ â–¶"):
            st.session_state.round_idx += 1  # ë¼ìš´ë“œ ì¸ë±ìŠ¤ ì¦ê°€
            st.session_state.last_out = None  # ë§ˆì§€ë§‰ ì¶œë ¥ ì´ˆê¸°í™”
            st.rerun()  # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨

# ==================== í‘¸í„° / ë‹¤ìš´ë¡œë“œ ====================
st.markdown("---")  # êµ¬ë¶„ì„ 
st.subheader("ğŸ“¥ ë¡œê·¸ ë‹¤ìš´ë¡œë“œ")  # ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ ì œëª©

# ë¡œê·¸ê°€ ìˆìœ¼ë©´ CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ í‘œì‹œ
if st.session_state.log:
    output = io.StringIO()  # ë¬¸ìì—´ ë²„í¼ ìƒì„±
    # CSV ì‘ì„±ê¸° ìƒì„± (ì²« ë¡œê·¸ì˜ í‚¤ë¥¼ í•„ë“œëª…ìœ¼ë¡œ ì‚¬ìš©)
    writer = csv.DictWriter(output, fieldnames=list(st.session_state.log[0].keys()))
    writer.writeheader()  # í—¤ë” ì‘ì„±
    writer.writerows(st.session_state.log)  # ëª¨ë“  ë¡œê·¸ ì‘ì„±
    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    st.download_button(
        "CSV ë‚´ë ¤ë°›ê¸°",
        data=output.getvalue().encode("utf-8"),  # UTF-8 ì¸ì½”ë”©
        file_name="ethical_crossroads_log.csv",  # íŒŒì¼ëª…
        mime="text/csv"  # MIME íƒ€ì…
    )

# ìµœì¢… ê³ ì§€ì‚¬í•­
st.caption("â€» ë³¸ ì•±ì€ êµìœ¡Â·ì—°êµ¬ìš© ì‚¬ê³ ì‹¤í—˜ì…ë‹ˆë‹¤. ì‹¤ì œ ìœ„í•´ í–‰ìœ„ë‚˜ ì°¨ë³„ì„ ê¶Œì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
