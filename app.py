# streamlit_app.py â€“ Cultural Ethics Simulator
import streamlit as st

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.spatial.distance import pdist
from scipy.stats import entropy, pearsonr


st.set_page_config(page_title="Ethics GPT Sim", layout="wide")
st.title("ğŸŒ Global AI Ethics Simulator")

# ----------------------------- Configuration -----------------------------
CULTURES = {
    "USA":     {"emotion": 0.3, "social": 0.1, "identity": 0.3, "moral": 0.3},
    "CHINA":   {"emotion": 0.1, "social": 0.5, "identity": 0.2, "moral": 0.2},
    "EUROPE":  {"emotion": 0.3, "social": 0.2, "identity": 0.2, "moral": 0.3},
    "KOREA":   {"emotion": 0.2, "social": 0.2, "identity": 0.4, "moral": 0.2},
    "LATIN_AM": {"emotion": 0.4, "social": 0.2, "identity": 0.2, "moral": 0.2},
    "MIDDLE_E": {"emotion": 0.1, "social": 0.2, "identity": 0.2, "moral": 0.5},
    "AFRICA":  {"emotion": 0.2, "social": 0.4, "identity": 0.2, "moral": 0.2},
}

scenario = st.sidebar.selectbox("ì‹œë‚˜ë¦¬ì˜¤", ["Classic Trolley", "Medical Triage", "AI Regulation"])
selected = st.sidebar.multiselect("ë¬¸í™”ê¶Œ ì„ íƒ", list(CULTURES.keys()), default=list(CULTURES.keys()))
steps = st.sidebar.slider("ë°˜ë³µ ìˆ˜", 50, 500, 200, step=50)
manual = st.sidebar.checkbox("ğŸ® ì‚¬ìš©ì ì •ì˜ ê°€ì¤‘ì¹˜", False)

def normalize(w):
    s = sum(w.values())
    return {k: max(0.001, v)/s for k, v in w.items()}

AGENTS = selected
AGENT_WEIGHTS = {}
for a in AGENTS:
    if manual:
        st.sidebar.markdown(f"**{a}**")
        w = {k: st.sidebar.slider(f"{a} - {k.capitalize()}", 0.0, 1.0, CULTURES[a][k]) for k in ["emotion", "social", "identity", "moral"]}
        AGENT_WEIGHTS[a] = normalize(w)
    else:
        AGENT_WEIGHTS[a] = dict(CULTURES[a])

AGENT_SCORES = {a: [] for a in AGENTS}
AGENT_HISTORY = {a: [dict(AGENT_WEIGHTS[a])] for a in AGENTS}
AGENT_ENTROPIES = {a: [] for a in AGENTS}
AGENT_MOVEMENT = {a: [] for a in AGENTS}
GROUP_DIVERGENCE = []
GROUP_AVG_REWARDS = []

# ----------------------------- Simulation -----------------------------
def simulate():
    for _ in range(steps):
        for a in AGENTS:
            prev = list(AGENT_WEIGHTS[a].values())
            r = np.random.rand(4)
            keys = list(AGENT_WEIGHTS[a].keys())
            score = sum(AGENT_WEIGHTS[a][k]*v for k,v in zip(keys, r))
            AGENT_SCORES[a].append(score)
            max_i, min_i = np.argmax(r), np.argmin(r)
            AGENT_WEIGHTS[a][keys[max_i]] += 0.05
            AGENT_WEIGHTS[a][keys[min_i]] -= 0.05
            AGENT_WEIGHTS[a] = normalize(AGENT_WEIGHTS[a])
            curr = list(AGENT_WEIGHTS[a].values())
            AGENT_HISTORY[a].append(dict(AGENT_WEIGHTS[a]))
            AGENT_ENTROPIES[a].append(entropy(curr))
            AGENT_MOVEMENT[a].append(np.linalg.norm(np.array(curr) - np.array(prev)))
        mat = np.array([list(AGENT_WEIGHTS[a].values()) for a in AGENTS])
        GROUP_DIVERGENCE.append(np.mean(pdist(mat)))
        GROUP_AVG_REWARDS.append(np.mean([np.mean(AGENT_SCORES[a]) for a in AGENTS]))

# ----------------------------- Display -----------------------------
def show_alerts():
    for a in AGENTS:
        if len(AGENT_ENTROPIES[a]) > 1:
            delta = AGENT_ENTROPIES[a][-2] - AGENT_ENTROPIES[a][-1]
            if delta > 0.1:
                st.warning(f"âš ï¸ {a}: ì „ëµì´ ê¸‰ê²©íˆ ì§‘ì¤‘ë˜ê³  ìˆìŠµë‹ˆë‹¤ (entropy â†“ {delta:.2f})")

@st.cache_data(show_spinner=False)
def generate_caption():
    return {
        "fig1": "Figure 1: Trajectories of strategic dimensions (Emotion, Social, Identity, Moral) per culture",
        "fig2": "Figure 2a: Entropy trends (internal diversity); 2b: Cumulative change of strategies",
        "fig3": "Figure 3a: Group divergence over time; 3b: Correlation with average reward"
    }

def gpt_summary():
    try:
        openai.api_key = st.secrets.get("OPENAI_API_KEY")
        trend = pd.DataFrame(GROUP_DIVERGENCE).diff().mean().values[0]
        agents = list(AGENT_HISTORY.keys())
        prompt = f"ë¬¸í™”ê¶Œ ì—ì´ì „íŠ¸ {agents}ê°€ ì „ëµ ê¶¤ì ì„ í•™ìŠµí•œ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ë¥¼ ìš”ì•½í•´ì¤˜. ì „ëµ ë‹¤ì–‘ì„±ê³¼ ë³´ìƒì˜ ê´€ê³„ë„ í¬í•¨í•´ì„œ 5ì¤„ë¡œ ì •ë¦¬í•´ì¤˜."
        out = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        st.info(out["choices"][0]["message"]["content"])
    except Exception as e:
        st.error(f"GPT ìš”ì•½ ì‹¤íŒ¨: {e}")

# ----------------------------- Run -----------------------------
if st.button("â–¶ï¸ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘"):
    simulate()
    captions = generate_caption()
    st.subheader("ğŸ“Š " + captions["fig1"])
    for dim in ["emotion", "social", "identity", "moral"]:
        fig, ax = plt.subplots()
        for a in AGENT_HISTORY:
            ax.plot([w[dim] for w in AGENT_HISTORY[a]], label=a)
        ax.set_title(f"{dim.capitalize()} Weight")
        ax.legend(); st.pyplot(fig)

    st.subheader("ğŸ“ˆ " + captions["fig2"])
    fig1, ax1 = plt.subplots()
    for a in AGENT_ENTROPIES:
        ax1.plot(AGENT_ENTROPIES[a], label=a)
    ax1.set_title("Entropy of Strategy Distribution")
    ax1.legend(); st.pyplot(fig1)

    fig2, ax2 = plt.subplots()
    for a in AGENT_MOVEMENT:
        ax2.plot(np.cumsum(AGENT_MOVEMENT[a]), label=a)
    ax2.set_title("Cumulative Strategic Change")
    ax2.legend(); st.pyplot(fig2)

    st.subheader("ğŸ“‰ " + captions["fig3"])
    fig3, ax3 = plt.subplots()
    ax3.plot(GROUP_DIVERGENCE, label="Ethical Divergence")
    ax3.set_title("Group Ethical Divergence")
    ax3.legend(); st.pyplot(fig3)

    fig4, ax4 = plt.subplots()
    ax4.scatter(GROUP_DIVERGENCE, GROUP_AVG_REWARDS)
    r, p = pearsonr(GROUP_DIVERGENCE, GROUP_AVG_REWARDS)
    ax4.set_title(f"Divergence vs Avg Reward (r={r:.2f}, p={p:.3f})")
    st.pyplot(fig4)

    st.subheader("ğŸ“„ ì „ëµ ìš”ì•½")
    df = pd.DataFrame([{"Agent": a, **AGENT_HISTORY[a][-1]} for a in AGENTS])
    st.dataframe(df.set_index("Agent"))
    st.download_button("ğŸ“¥ Save CSV", data=df.to_csv(index=False), file_name="final_strategies.csv")

    st.subheader("ğŸ“¡ ì „ëµ ë¶„ê¸° ê²½ê³ ")
    show_alerts()


# app.py â€” Ethical Crossroads (UI ê°œì„  ë° ì„ íƒ â†’ ê²°ì • êµ¬ì¡° ì ìš©)
# Updated by ChatGPT for Yoon Jaeeun

import os, json, math, csv, io, datetime as dt, re
from dataclasses import dataclass
from typing import Dict, Any, List, Tuple, Optional

import streamlit as st
import httpx
from tenacity import retry, wait_exponential, stop_after_attempt, retry_if_exception_type

# =======================================================
# Streamlit ê¸°ë³¸ ì„¤ì •
# =======================================================
st.set_page_config(page_title="ìœ¤ë¦¬ì  ì „í™˜ (Ethical Crossroads)", page_icon="ğŸ§­", layout="centered")

HTTPX_TIMEOUT = httpx.Timeout(connect=15.0, read=180.0, write=30.0, pool=15.0)

def clamp(x: float, lo: float, hi: float) -> float:
    return max(lo, min(hi, x))

def coerce_json(s: str) -> Dict[str, Any]:
    s = s.strip()
    m = re.search(r"\{[\s\S]*\}", s)
    if not m:
        raise ValueError("JSON ë¸”ë¡ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    js = m.group(0)
    js = re.sub(r",\s*([\]}])", r"\1", js)
    return json.loads(js)

def get_secret(k: str, default: str=""):
    try:
        return st.secrets.get(k, os.getenv(k, default))
    except Exception:
        return os.getenv(k, default)


# =======================================================
# Scenario ëª¨ë¸
# =======================================================
@dataclass
class Scenario:
    sid: str
    title: str
    setup: str
    options: Dict[str, str]
    votes: Dict[str, str]
    base: Dict[str, Dict[str, float]]
    accept: Dict[str, float]

FRAMEWORKS = ["emotion", "social", "moral", "identity"]

# =======================================================
# ê¸°ë³¸ ì‹œë‚˜ë¦¬ì˜¤ (ê¸°ì¡´ 5ê°œ ìœ ì§€)
# =======================================================
SCENARIOS = [
    Scenario(
        sid="S1",
        title="1ë‹¨ê³„: ê³ ì „ì  íŠ¸ë¡¤ë¦¬",
        setup="íŠ¸ë¡¤ë¦¬ê°€ ì œë™ ë¶ˆëŠ¥ ìƒíƒœë¡œ ì§ì§„ ì¤‘. ê·¸ëŒ€ë¡œ ë‘ë©´ ì„ ë¡œ ìœ„ 5ëª…ì´ ìœ„í—˜í•˜ë‹¤. "
              "ìŠ¤ìœ„ì¹˜ë¥¼ ì „í™˜í•˜ë©´ ë‹¤ë¥¸ ì„ ë¡œì˜ 1ëª…ì´ ìœ„í—˜í•´ì§„ë‹¤.",
        options={
            "A": "ë ˆë²„ë¥¼ ë‹¹ê²¨ 1ëª…ì„ ìœ„í—˜ì— ì²˜í•˜ê²Œ í•˜ë˜ 5ëª…ì˜ ìœ„í—˜ì„ ì¤„ì¸ë‹¤.",
            "B": "ë ˆë²„ë¥¼ ë‹¹ê¸°ì§€ ì•Šê³  í˜„ ìƒíƒœë¥¼ ìœ ì§€í•œë‹¤."
        },
        votes={"emotion":"A","social":"B","moral":"B","identity":"A"},
        base={
            "A": {"lives_saved":5, "lives_harmed":1, "fairness_gap":0.35, "rule_violation":0.60, "regret_risk":0.40},
            "B": {"lives_saved":0, "lives_harmed":5, "fairness_gap":0.50, "rule_violation":0.20, "regret_risk":0.60},
        },
        accept={"A":0.70, "B":0.50}
    ),
    # (ìƒëµ: ê¸°ì¡´ S2~S5 ê·¸ëŒ€ë¡œ)
]


# =======================================================
# ê°€ì¤‘ì¹˜ ê³„ì‚° í•¨ìˆ˜
# =======================================================
def normalize_weights(w: Dict[str, float]) -> Dict[str, float]:
    s = sum(max(0.0, float(v)) for v in w.values())
    return {k: max(0.0, float(v))/s for k, v in w.items()}


# =======================================================
# ìœ¤ë¦¬ ì—”ì§„ ê³„ì‚° (ê¸°ì¡´ ìœ ì§€)
# =======================================================
def compute_metrics(scn: Scenario, choice: str, weights: Dict[str, float], align: Dict[str, float], prev_trust: float):
    m = dict(scn.base[choice])
    accept_base = scn.accept[choice]
    util = (m["lives_saved"] - m["lives_harmed"]) / max(1.0, m["lives_saved"] + m["lives_harmed"])

    citizen_sentiment = clamp(accept_base - 0.35*m["rule_violation"] - 0.20*m["fairness_gap"] + 0.15*util, 0, 1)
    regulation_pressure = clamp(1 - citizen_sentiment + 0.20*m["regret_risk"], 0, 1)
    stakeholder_satisfaction = clamp(0.5*(1 - m["fairness_gap"]) + 0.3*util + 0.2*(1 - m["rule_violation"]), 0, 1)

    consistency = clamp(align[choice], 0, 1)
    trust = clamp(0.5*citizen_sentiment + 0.25*(1 - regulation_pressure) + 0.25*stakeholder_satisfaction, 0, 1)
    ai_trust_score = 100.0 * math.sqrt(consistency * trust)

    return {
        "metrics": {
            "lives_saved": m["lives_saved"],
            "lives_harmed": m["lives_harmed"],
            "fairness_gap": m["fairness_gap"],
            "rule_violation": m["rule_violation"],
            "regret_risk": m["regret_risk"],
            "citizen_sentiment": citizen_sentiment,
            "regulation_pressure": regulation_pressure,
            "stakeholder_satisfaction": stakeholder_satisfaction,
            "ethical_consistency": consistency,
            "social_trust": trust,
            "ai_trust_score": round(ai_trust_score, 2)
        }
    }


# =======================================================
# ì„¸ì…˜ ì´ˆê¸°í™”
# =======================================================
def init_state():
    if "round_idx" not in st.session_state: st.session_state.round_idx = 0
    if "log" not in st.session_state: st.session_state.log = []
    if "prev_trust" not in st.session_state: st.session_state.prev_trust = 0.5
init_state()


# =======================================================
# UI ì‹œì‘
# =======================================================
st.title("ğŸ§­ ìœ¤ë¦¬ì  ì „í™˜ (Ethical Crossroads)")
st.caption("ìœ¤ë¦¬ ì‹œë®¬ë ˆì´í„° â€” ì‹œë‚˜ë¦¬ì˜¤ ì½ê¸° â†’ ì„ íƒ â†’ ê²°ì • ê²°ê³¼ í™•ì¸")

idx = st.session_state.round_idx

if idx >= len(SCENARIOS):
    st.success("ëª¨ë“  ë‹¨ê³„ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤! ì‚¬ì´ë“œë°”ì—ì„œ ë¡œê·¸ë¥¼ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    st.stop()

scn = SCENARIOS[idx]

# ===============================
# ì‹œë‚˜ë¦¬ì˜¤ í‘œì‹œ (í•­ìƒ ë¨¼ì € ë³´ì„)
# ===============================
st.subheader(f"ë¼ìš´ë“œ {idx+1} â€” {scn.title}")
st.write(scn.setup)

st.markdown("### ğŸ“ ì„ íƒì§€")
st.write(f"#### A) {scn.options['A']}")
st.write(f"#### B) {scn.options['B']}")

# ì‚¬ìš©ì ì„ íƒ UI
user_choice = st.radio("ë‹¹ì‹ ì˜ ì„ íƒì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?", ["A", "B"], horizontal=True)

st.markdown("---")

# ===============================
# ğŸ”˜ ê²°ì • ë²„íŠ¼
# ===============================
if st.button("ğŸš€ ê²°ì •í•˜ê¸°"):
    decision = user_choice

    align = {
        "A": sum(1 for k in FRAMEWORKS if scn.votes[k] == "A"),
        "B": sum(1 for k in FRAMEWORKS if scn.votes[k] == "B"),
    }

    computed = compute_metrics(scn, decision, {"emotion":0.25,"social":0.25,"moral":0.25,"identity":0.25}, align, st.session_state.prev_trust)
    m = computed["metrics"]

    st.success(f"ë‹¹ì‹ ì˜ ì„ íƒ: {decision}")

    st.subheader("ğŸ“˜ ê²°ê³¼ ìš”ì•½")
    st.write(f"- ìƒì¡´/í”¼í•´: **{m['lives_saved']} / {m['lives_harmed']}**")
    st.write(f"- ìœ¤ë¦¬ ì¼ê´€ì„±: **{round(100*m['ethical_consistency'])}%**")
    st.write(f"- AI ì‹ ë¢°ì§€í‘œ: **{m['ai_trust_score']}ì **")

    st.markdown("---")

    st.session_state.log.append({
        "round": idx+1,
        "scenario": scn.sid,
        "choice": decision,
        **m
    })
    st.session_state.prev_trust = m["social_trust"]

    if st.button("â–¶ ë‹¤ìŒ ë¼ìš´ë“œ"):
        st.session_state.round_idx += 1
        st.rerun()


# =======================================================
# ë‹¤ìš´ë¡œë“œ
# =======================================================
st.markdown("---")
st.subheader("ğŸ“¥ ë¡œê·¸ ë‹¤ìš´ë¡œë“œ")

if st.session_state.log:
    output = io.StringIO()
    fieldnames = list(st.session_state.log[0].keys())
    writer = csv.DictWriter(output, fieldnames=fieldnames)
    writer.writeheader()
    writer.writerows(st.session_state.log)

    st.download_button(
        "CSV ì €ì¥í•˜ê¸°",
        data=output.getvalue().encode("utf-8"),
        file_name="log.csv",
        mime="text/csv"
    )
