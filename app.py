# streamlit_app.py â€“ Cultural Ethics Simulator
import streamlit as st

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from dataclasses import dataclass
from scipy.spatial.distance import pdist
from scipy.stats import entropy, pearsonr


st.set_page_config(page_title="Ethics GPT Sim", layout="wide")
st.title("ğŸŒ Global AI Ethics Simulator")

# ----------------------------- Configuration -----------------------------
CULTURES = {
    "USA":     {"emotion": 0.3, "social": 0.1, "identity": 0.3, "moral": 0.3},
    "CHINA":   {"emotion": 0.1, "social": 0.5, "identity": 0.2, "moral": 0.2},
    "EUROPE":  {"emotion": 0.3, "social": 0.2, "identity": 0.2, "moral": 0.3},
    "KOREA":   {"emotion": 0.2, "social": 0.2, "identity": 0.4, "moral": 0.2},
    "LATIN_AM": {"emotion": 0.4, "social": 0.2, "identity": 0.2, "moral": 0.2},
    "MIDDLE_E": {"emotion": 0.1, "social": 0.2, "identity": 0.2, "moral": 0.5},
    "AFRICA":  {"emotion": 0.2, "social": 0.4, "identity": 0.2, "moral": 0.2},
}

scenario = st.sidebar.selectbox("ì‹œë‚˜ë¦¬ì˜¤", ["Classic Trolley", "Medical Triage", "AI Regulation"])
selected = st.sidebar.multiselect("ë¬¸í™”ê¶Œ ì„ íƒ", list(CULTURES.keys()), default=list(CULTURES.keys()))
steps = st.sidebar.slider("ë°˜ë³µ ìˆ˜", 50, 500, 200, step=50)
manual = st.sidebar.checkbox("ğŸ® ì‚¬ìš©ì ì •ì˜ ê°€ì¤‘ì¹˜", False)

def normalize(w):
    s = sum(w.values())
    return {k: max(0.001, v)/s for k, v in w.items()}

AGENTS = selected
AGENT_WEIGHTS = {}
for a in AGENTS:
    if manual:
        st.sidebar.markdown(f"**{a}**")
        w = {k: st.sidebar.slider(f"{a} - {k.capitalize()}", 0.0, 1.0, CULTURES[a][k]) for k in ["emotion", "social", "identity", "moral"]}
        AGENT_WEIGHTS[a] = normalize(w)
    else:
        AGENT_WEIGHTS[a] = dict(CULTURES[a])

AGENT_SCORES = {a: [] for a in AGENTS}
AGENT_HISTORY = {a: [dict(AGENT_WEIGHTS[a])] for a in AGENTS}
AGENT_ENTROPIES = {a: [] for a in AGENTS}
AGENT_MOVEMENT = {a: [] for a in AGENTS}
GROUP_DIVERGENCE = []
GROUP_AVG_REWARDS = []

# ----------------------------- Simulation -----------------------------
def simulate():
    for _ in range(steps):
        for a in AGENTS:
            prev = list(AGENT_WEIGHTS[a].values())
            r = np.random.rand(4)
            keys = list(AGENT_WEIGHTS[a].keys())
            score = sum(AGENT_WEIGHTS[a][k]*v for k,v in zip(keys, r))
            AGENT_SCORES[a].append(score)
            max_i, min_i = np.argmax(r), np.argmin(r)
            AGENT_WEIGHTS[a][keys[max_i]] += 0.05
            AGENT_WEIGHTS[a][keys[min_i]] -= 0.05
            AGENT_WEIGHTS[a] = normalize(AGENT_WEIGHTS[a])
            curr = list(AGENT_WEIGHTS[a].values())
            AGENT_HISTORY[a].append(dict(AGENT_WEIGHTS[a]))
            AGENT_ENTROPIES[a].append(entropy(curr))
            AGENT_MOVEMENT[a].append(np.linalg.norm(np.array(curr) - np.array(prev)))
        mat = np.array([list(AGENT_WEIGHTS[a].values()) for a in AGENTS])
        GROUP_DIVERGENCE.append(np.mean(pdist(mat)))
        GROUP_AVG_REWARDS.append(np.mean([np.mean(AGENT_SCORES[a]) for a in AGENTS]))

# ----------------------------- Display -----------------------------
def show_alerts():
    for a in AGENTS:
        if len(AGENT_ENTROPIES[a]) > 1:
            delta = AGENT_ENTROPIES[a][-2] - AGENT_ENTROPIES[a][-1]
            if delta > 0.1:
                st.warning(f"âš ï¸ {a}: ì „ëµì´ ê¸‰ê²©íˆ ì§‘ì¤‘ë˜ê³  ìˆìŠµë‹ˆë‹¤ (entropy â†“ {delta:.2f})")

@st.cache_data(show_spinner=False)
def generate_caption():
    return {
        "fig1": "Figure 1: Trajectories of strategic dimensions (Emotion, Social, Identity, Moral) per culture",
        "fig2": "Figure 2a: Entropy trends (internal diversity); 2b: Cumulative change of strategies",
        "fig3": "Figure 3a: Group divergence over time; 3b: Correlation with average reward"
    }

def gpt_summary():
    try:
        openai.api_key = st.secrets.get("OPENAI_API_KEY")
        trend = pd.DataFrame(GROUP_DIVERGENCE).diff().mean().values[0]
        agents = list(AGENT_HISTORY.keys())
        prompt = f"ë¬¸í™”ê¶Œ ì—ì´ì „íŠ¸ {agents}ê°€ ì „ëµ ê¶¤ì ì„ í•™ìŠµí•œ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ë¥¼ ìš”ì•½í•´ì¤˜. ì „ëµ ë‹¤ì–‘ì„±ê³¼ ë³´ìƒì˜ ê´€ê³„ë„ í¬í•¨í•´ì„œ 5ì¤„ë¡œ ì •ë¦¬í•´ì¤˜."
        out = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        st.info(out["choices"][0]["message"]["content"])
    except Exception as e:
        st.error(f"GPT ìš”ì•½ ì‹¤íŒ¨: {e}")

# ----------------------------- Run -----------------------------
if st.button("â–¶ï¸ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘"):
    simulate()
    captions = generate_caption()
    st.subheader("ğŸ“Š " + captions["fig1"])
    for dim in ["emotion", "social", "identity", "moral"]:
        fig, ax = plt.subplots()
        for a in AGENT_HISTORY:
            ax.plot([w[dim] for w in AGENT_HISTORY[a]], label=a)
        ax.set_title(f"{dim.capitalize()} Weight")
        ax.legend(); st.pyplot(fig)

    st.subheader("ğŸ“ˆ " + captions["fig2"])
    fig1, ax1 = plt.subplots()
    for a in AGENT_ENTROPIES:
        ax1.plot(AGENT_ENTROPIES[a], label=a)
    ax1.set_title("Entropy of Strategy Distribution")
    ax1.legend(); st.pyplot(fig1)

    fig2, ax2 = plt.subplots()
    for a in AGENT_MOVEMENT:
        ax2.plot(np.cumsum(AGENT_MOVEMENT[a]), label=a)
    ax2.set_title("Cumulative Strategic Change")
    ax2.legend(); st.pyplot(fig2)

    st.subheader("ğŸ“‰ " + captions["fig3"])
    fig3, ax3 = plt.subplots()
    ax3.plot(GROUP_DIVERGENCE, label="Ethical Divergence")
    ax3.set_title("Group Ethical Divergence")
    ax3.legend(); st.pyplot(fig3)

    fig4, ax4 = plt.subplots()
    ax4.scatter(GROUP_DIVERGENCE, GROUP_AVG_REWARDS)
    r, p = pearsonr(GROUP_DIVERGENCE, GROUP_AVG_REWARDS)
    ax4.set_title(f"Divergence vs Avg Reward (r={r:.2f}, p={p:.3f})")
    st.pyplot(fig4)

    st.subheader("ğŸ“„ ì „ëµ ìš”ì•½")
    df = pd.DataFrame([{"Agent": a, **AGENT_HISTORY[a][-1]} for a in AGENTS])
    st.dataframe(df.set_index("Agent"))
    st.download_button("ğŸ“¥ Save CSV", data=df.to_csv(index=False), file_name="final_strategies.csv")

    st.subheader("ğŸ“¡ ì „ëµ ë¶„ê¸° ê²½ê³ ")
    show_alerts()


# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'round_idx' not in st.session_state:
    st.session_state.round_idx = 0
# ==================== Game Loop ====================
@dataclass
class LogRow:
    timestamp: str
    round: int
    scenario_id: str
    title: str
    mode: str
    choice: str

idx = st.session_state.round_idx

if idx >= len(SCENARIOS):
    st.success("ëª¨ë“  ë‹¨ê³„ë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ë¡œê·¸ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê±°ë‚˜ ì´ˆê¸°í™”í•˜ì„¸ìš”.")
else:
    scn = SCENARIOS[idx]

    st.markdown(f"### ë¼ìš´ë“œ {idx+1} â€” {scn.title}")
    st.write(scn.setup)

    st.markdown("#### ğŸ“ ì„ íƒì§€")
    st.write(f"**A:** {scn.options['A']}")
    st.write(f"**B:** {scn.options['B']}")

    # ë¼ë””ì˜¤ ë²„íŠ¼ìœ¼ë¡œ ì„ íƒ ë¨¼ì € ì§„í–‰
    user_choice = st.radio("ë‹¹ì‹ ì˜ ì„ íƒì€?", ("A", "B"), horizontal=True, key=f"user_choice_{idx}")

    st.markdown("---")

    decide_btn = st.button("ğŸš€ ê²°ì •í•˜ê¸°")

    if decide_btn:
        # ì‚¬ìš©ìê°€ ì„ íƒí•œ ê·¸ëŒ€ë¡œ ë°˜ì˜
        decision = user_choice
        
        # alignment ê³„ì‚° (ê°€ì¤‘ì¹˜ ê¸°ë°˜)
        align = {
            "A": sum(weights[f] for f in FRAMEWORKS if scn.votes[f] == "A"),
            "B": sum(weights[f] for f in FRAMEWORKS if scn.votes[f] == "B"),
        }

        computed = compute_metrics(scn, decision, weights, align, st.session_state.prev_trust)
        m = computed["metrics"]

        # ë‚´ëŸ¬í‹°ë¸Œ ìƒì„±
        try:
            if client:
                nar = dna_narrative(client, scn, decision, m, weights)
            else:
                nar = fallback_narrative(scn, decision, m, weights)
        except:
            nar = fallback_narrative(scn, decision, m, weights)

        st.subheader("ğŸ“˜ ê²°ê³¼")
        st.write(nar.get("narrative", "ê²°ê³¼ ìƒì„± ì‹¤íŒ¨"))
        st.info(f"AI ê·¼ê±°: {nar.get('ai_rationale', '-')}")
        
        mc1, mc2, mc3 = st.columns(3)
        mc1.metric("ìƒì¡´/í”¼í•´", f"{m['lives_saved']} / {m['lives_harmed']}")
        mc2.metric("ìœ¤ë¦¬ ì¼ê´€ì„±", f"{int(100*m['ethical_consistency'])}%")
        mc3.metric("AI ì‹ ë¢°ì§€í‘œ", f"{m['ai_trust_score']:.1f}")

        st.markdown("---")
        st.caption("ğŸ“° ì‚¬íšŒì  ë°˜ì‘")
        st.write(f"ì§€ì§€ í—¤ë“œë¼ì¸: {nar.get('media_support_headline')}")
        st.write(f"ë¹„íŒ í—¤ë“œë¼ì¸: {nar.get('media_critic_headline')}")
        st.write(f"ì‹œë¯¼ ë°˜ì‘: {nar.get('citizen_quote')}")
        st.write(f"í”¼í•´ì ê°€ì¡±: {nar.get('victim_family_quote')}")
        st.write(f"ê·œì œê¸°ê´€: {nar.get('regulator_quote')}")
        st.caption(nar.get("one_sentence_op_ed", ""))

        st.session_state.log.append({
            "timestamp": dt.datetime.utcnow().isoformat(timespec="seconds"),
            "round": idx+1,
            "scenario_id": scn.sid,
            "title": scn.title,
            "mode": "user_choice",
            "choice": decision,
            **{k: m[k] for k in m}
        })

        st.session_state.prev_trust = clamp(
            0.6 * st.session_state.prev_trust + 0.4 * m["social_trust"],
            0, 1
        )

        st.markdown("---")
        if st.button("â–¶ ë‹¤ìŒ ë¼ìš´ë“œ"):
            st.session_state.round_idx += 1
            st.rerun()
